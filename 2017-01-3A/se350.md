# SE 350: Operating Systems

Professor: Sebastian Fischmeister.

I used to have nicely written notes, but since the course content is kind of just a collection of facts, I'm just summarizing likely-testable material from the textbook.

Lectures are good for seeing cool demos with fsize 35 and emacs and for gaining an appreciation for life. Not good for learning the things that will be on quizzes, which is unfortunately what matters.

### Cool Demos Man

### Ch 3

- 2017-01-24: Multithreading with pthread, passing pointer to local stack, race condition.
- 2017-01-24: pth\_burner.c
  - User-level threads with pth.
  - Only one thread works, is never blocked so never hands off control.
- 2017-01-24: pthreads\_burner.c: Kernel-level threads. All threads run at a time. I/O works.

### Ch 1: Computers

- Four parts of a computer
  - CPU
  - Main memory
  - I/O modules
  - System bus
- Four general types of instruction
  - Processor-memory
  - Processor-I/O
  - Data processing (math)
  - Control
- Four types of interrupt
  - Exceptions
  - Timer
  - I/O
  - Hardware failure
- Registers
  - Memory address register (MAR):
    - Specifies address in memory for next I/O operation
  - Memory buffer register (MBR):
    - Contains data that needs to be written to, or that was read from, memory
  - I/O address register (I/OAR), I/OBR:
    - Specifies the I/O device and contains data for I/O
- Reentrant procedure: Single copy of code can be shared by many users
- Interrupt processing
  - Processor saves PSW, PC onto a control stack
  - Interrupt handler saves all other registers onto the control stack
  - Interrupt handler restores saved register values
  - Processor restores PSW, PC
- Ways to handle multiple interrupts
  - Disable interrupt in interrupt handlers
  - Prioritize interrupts and push lower-priority handler contexts onto a stack
- Memory hierarchy
  - Register, cache, primary, secondary
  - Locality of reference: Memory references cluster due to loops
    - Spatial locality: Sequentially accessed memory locations tend to be clustered (or themselves sequential)
    - Temporal locality: Recently used memory locations tend to be used again
- Cache memory
  - Cache size
    - Main memory has 2^n words
    - Main memory broken up into 2^n / K blocks of size K
    - Cache has C slots of K words each, C << M
  - Block size
  - Mapping function
  - Replacement algorithm (LRU > FIFO > random)
  - Write policy
  - Hit ratio: Percent of memory accesses that hit the cache
- I/O
  - Programmed I/O: processor polls I/O module
  - Interrupt-driven I/O: I/O module interrupts when ready
  - Direct memory access: DMA module (not necessarily same as I/O module) interacts with memory directly
- Multiprocessor
  - SMP: Similar processors, share memory and I/O

### Ch 2: Operating systems

- Operating system goals (ACE)
  - Ability to evolve -- be a good abstraction
  - Convenience -- make computer easier to use
  - Efficiency -- better utilize computer
- History
  - Serial processing: Scheduling and setup
  - Batch systems
    - Monitor. Programs branch back to it when finishing, and it decides which program to run next.
      - Resident monitor: part that controls sequence of events.
      - Also has utils and functions
    - Job control language: instructions for the monitor
    - Hardware features:
      - Memory protection
      - Timer
      - Privileged instructions
        - One consequence: Monitor retains control of I/O devices
        - Introduces user mode and kernel mode
      - Interrupts
  - Multiprogrammed batch system
    - Multiprogramming / multitasking:
      - Multiple programs at once
      - Switch between them when waiting on I/O
    - Uniprogramming is not multiprogramming
  - Time sharing systems
    - For interactive things
    - Interleave user time in short bursts
    - Time slicing: Using clock interrupts to reassign CPU control
- Process: Program, execution context (process state), and resources
  - Four main causes of errors (FIND):
    - Failed mutual exclusion (of shared resources)
    - Improper synchronization (of I/O)
    - Nondeterminate program operation: programs screwing with other programs' memory space and affecting their operation
    - Deadlocks: programs waiting on each other in a loop
  - Steps in context switch:
    - Save context
    - Update PCB of currently running process (incl. change state to not running)
    - Move PCB to appropriate queue
    - Schedule (select another process)
    - Update PCB of selected process (incl. change state to running)
    - Update memory management data structures
    - Restore context
- Memory management:
  - Roles of the OS (APPLS):
    - Automatic allocation
    - Process isolation
    - Protection and access control (for shared memory)
    - Long-term storage
    - Support modular programming
  - Virtual address: Page number and offset
  - Real address / Physical address: Actual address
- Security and protection (ACDA)
  - Availability
  - Confidentiality
  - Data integrity
  - Authenticity
- Resource management factors: (FED)
  - Fairness (Proccesses of the same class have fair and equal access to resources)
  - Efficiency: Maximum throughput, minimize response time
  - Differential responsiveness (More important processes have priority)
- Round-robin: Each process in a queue takes turns
- Modern OS developments
  - Microkernel: Kernel only has essential functions, unlike monolithic kernel
  - Multithreading
  - Symmetric multiprocessing
    - Advantages over uniprocessor (PAIS):
      - Performance -- parallelizable work done faster
      - Availability -- failure of a single processor does not kill everything
      - Incremental growth -- add processors to make things faster
      - Scaling -- sell wider variety of computers by adding more processors
  - Distributed operating systems: Huh-doop like. Lol no.
  - Object-oriented design: Used in development
- Faults
  - Types
    - Permanent (e.g. failed disk)
    - Temporary
      - Transient (e.g. RAM bit flip)
      - Intermittent (e.g. loose connection)
  - Fault tolerance
    - Reliability R(t) is probability system is still up after t time.
    - MTTF: Mean time to failure. Average time system stays up. = Integral 0 to infinity of R(t)
    - MTTR: Mean time to repair. Average time system stays down.
    - Availability: Fraction of time the system is up. = MTTF / (MTTF + MTTR)
  - Types of redundancy (STI)
    - Spatial / physical (e.g. backup server)
    - Temporal (e.g. retransmission)
    - Information (e.g. RAID)
  - Fault tolerance in OSes (PCVC)
    - Process isolation
    - Concurrency controls
    - Virtual machines
    - Checkpoints and rollbacks
- Multiprocessor / Multicore
  - Considerations (SSSRM):
    - Simultaneous concurrent processes / threads
    - Scheduling
    - Synchronization
    - Reliability / fault tolerance
    - Memory management
  - Grand Central Dispatch: Thread pool of lambdas
- Windows
  - Windows NT:
    - Executive: Memory management, processes, threads, security, I/O, IPC. Threaded.
    - Kernel: Processs execution, scheduling, switching, exceptions and interrupts, multiprocessor. Not threaded.
    - HAL: Maps generic hardware commands to platform-specific ones
    - Device drivers: Extend Executive.
- Unix
- Modern Unix
- Linux
  - Loadable modules
  - Signals (SIGKILL, SIGTERM, SIGINT, SIGSEGV, SIGTRAP)
  - Syscalls
- Android
  - Activities
  - Alarms

### Ch 3: Processes

- Control tables
  - **Process control block**: keeps track of a process.
    - Process identification
      - PID
    - Processor state
      - PC
    - Process control information
      - State
      - Priority
      - Memory pointers
      - Execution context
      - I/O status
    - Accounting?
  - **I/O tables** track I/O device status, source, destination
  - **File tables** track file location, status, etc.
- **Scheduler** picks which process to run next
- **Dispatcher** switches the processor from one process to another
- Process states
  - Two-state model: (Enter) -> Running -> (Dispatch) / <- (Pause) Not running (Exit) ->
  - Five-state model:
    - New (admit -> Ready)
      - Still in disk. Not yet committed to running in memory.
    - Ready (dispatch -> Running)
    - Running (time-out -> Ready, event wait -> Blocked, release -> Exit)
    - Blocked (event occurs -> Ready)
    - Exit
  - Seven-state model:
    - Split Ready and Blocked out to produce Ready / Suspend and Blocked / Suspend
    - Allows for better swapping processes back in
  - When one process spawns another, the spawned process is a child and the spawner is a parent
- Trace: Sequence of instructions
- Swapping: Use disk to store a process
- Process image: The collection of all data associated with a process, including its PCB, stack, program code, and data
- Modes:
  - User mode: Least privileged.
  - System mode / Control mode / Kernel mode: Most privileged.
  - Determined by bit in PSW.
- Reasons for process creation:
  - New batch job
  - Interactive log-on
  - Created by OS to service a user
  - Spawned
- Process creation process:
  - Assign PID.
  - Allocate space for stack, heap, PCB
  - Initialize PCB
  - Set up linkages
  - Set up other data structures
- When to switch processes:
  - Clock interrupt
  - I/O interrupt
  - Memory fault (addr outside of virtual memory range)
- Ways to interrupt process execution:
  - Interrupt
  - Trap: Using an error or exception to stop process at a certain point.
  - Supervisor call: system call
- Interrupt handling:
  - PC = interrupt handler (hardware)
  - Switch to kernel mode (hardware)
- Execution of the OS
  - Nonprocess kernel
  - Execute within user processes

### Ch 4: Threads

- Multithreading
  - Processes have multiple threads
  - Threads run independently
  - Threads share memory space
  - Advantages of threads:
    - Creating is faster
    - Terminating is faster
    - Switching is faster
    - Communication is faster: no IPC or kernel involved; just share RAM!
  - Uses of threads:
    - Foreground / Background work
    - Asynchronous processing
    - Making programs faster
    - Making programs more modular
  - Thread state operations:
    - Spawn: New thread put on ready queue
    - Block: Wait for event
    - Unblock: Event happens
    - Finish: Deallocate stuff
- Types of threads
  - User-level threads (ULT): Application manages threads
  - Kernel-level threads (KLT): Kernel manages threads
    - e.g. Windows
  - Advantages of ULT:
    - No mode switches
    - Application-specific scheduling
    - OS-agnostic
  - Advantages of KLT:
    - Blocking system calls don't block whole process
    - Allows for multiprocessing
- Jacketing: User-level wrapper around blocking syscall that makes it non-blocking by checking to see if resource is available first
- Thread-process ratios:
  - 1:1: e.g. UNIX
  - M:1: Processes have multiple threads e.g. Windows, Solaris, Linux
  - 1:M: Threads move between processes e.g. Ra (Clouds), Emerald
  - M:N: TRIX
- Multicore
  - Speedup is 1 / (1 - f + f/N)
    - f: amount of code that is parallel
    - N: number of cores
- Case studies
  - Valve
    - Coarse threading: Modules are separate threads. e.g. AI/Physics
    - Fine-grained threading: Loops are threads. Parallel loops.
    - Hybrid threading: Bit of both.
  - Windows
    - Job objects manage groups of processes
    - Fibers are user-scheduled units of execution
    - User-mode scheduling (UMS) allows apps to schedule their own threads
    - Metro: Suspending an app saves its state
    - Process object has:
      - Access token
      - Handle table for resources and I/O
      - Virtual address linked list
    - Process state model:
      - Ready: Can run
      - Standby: Chosen to run next
      - Running
      - Waiting: Blocked on event, or voluntarily waiting
      - Transition: Ready to run but resources not available
      - Terminated
  - Solaris
    - Processes
    - User-level threads
    - Lightweight processes: maps ULTs to kernel threads
    - Kernel threads
    - Process state model:
      - IDL
      - PINNED
      - RUN
      - ONPROC: preempted
      - SLEEP: blocked
      - STOP: stopped
      - ZOMBIE: thread has terminated
      - FREE: resources released
  - Linux
    - PCB is `task_struct`
    - Process state model:
      - Stopped
      - Running: Ready / Executing
      - Interruptible: Normal blocked, will handle signals
      - Uninterruptible: Special blocked, waiting on hardware and will not handle signals
      - Zombie
  - Android
    - Four types of components
      - Activities: foreground screens
      - Services: background tasks
      - Content providers: data
      - Broadcast receivers: warnings and stuff
    - Dedicated virtual machine for each application (sandboxing)
  - macOS
    - G r a n d   C e n t r a l   D i s p a t c h

### Ch 5: Concurrency: Mutual exclusion and synrhonization

- Key words
  - Atomic: a sequence of instructions that happens indivisibly
  - Critical section: code section that requires access to shared resources
  - Deadlock: multiple processes are blocked because each waits for the other
  - Livelock: multiple processes look busy but mutually do nothing useful
  - Mutual exclusion: only one process can access a shared resource at a time
  - Race condition: result changes depending on order of thread execution
  - Starvation: process never scheduled even though it can progress
- Process interaction
  - Competition: Unaware of each other. Not intended to work together.
  - Cooperation by sharing: Indirectly aware of each other by shared object.
  - Cooperation by communication: Directly aware of each other.
    - Communicate by PID and work jointly on an activity.
- Mutual exclusion
  - Software support
    - Dekker's algorithm in some library or OS/language support.
  - Hardware support
    - Disable interrupts to make a critical section atomic
      - Does not work if there is multiprocessing, multicore or multiprocessor.
    - Hardware-level atomic instructions to achieve mutual exclusion
      - compare&swap: replace a value iff it is equal to some test value
      - exchange: swap register and memory location atomically
  - Advantages of instructions:
    - Applicable to any number of processes
    - Simple, easy to verify
    - Multiple critical sections
  - Disadvantages of instructions:
    - Busy waiting
    - Starvation can happen
    - Deadlock can happen if higher priority process gets stuck in the busy loop
- Semaphore
  - Shared variable which can be atomically initialized, decremented, or incremented.
  - Operations
    - initialize: inits with non-negative value
    - semWait: decrements. blocks the caller if value becomes negative
    - semSignal: increments. unblocks a process if value is still now at most 0
  - No way to tell if semWait or semSignal will block/unblock a process!
  - Binary semaphore: values restricted to 0 or 1
    - Mutual exclusion lock (mutex):
      - Binary semaphore where the same process needs to take and release lock.
  - Strong semaphore: FIFO blocked queue. Free from starvation.
  - Weak semaphore: No order to pop from blocked queue. May starve.
  - Producer / consumer problem
    - Semaphores are hard. Get used to them.
    - Use local variables to prevent preemption from fucking shit up
- Monitor
  - A module with private local data. Only one process can be in the monitor at a time.
  - e.g. in Java, synchronized makes your thing a monitor
  - Condition variables within the monitor:
    - cwait(c): Suspend until condition c is signalled
    - csignal(c): Signals condition c
  - Equivalent in power to semaphores.
  - Hoare monitor: csignal blocks if there are no processes
  - Lampson/Redell monitor: use cnotify instead, which is like a non-blocking csignal
- Message passing
  - API:
    - send(destination, message)
    - receive(source, message)
  - Possible blocking semantics:
    - Blocking send, blocking receive.
      - aka rendezvous
      - Sender and receiver must coordinate
    - Nonblocking send, blocking receive.
      - Most useful, usually
    - Nonblocking send, nonblocking receive. (Kafka)
  - Possible addressing semantics:
    - Direct addressing
      - Sender: Destination is specific
      - Receiver: Source can be specific or unspecified
      - Explicit: Receiver must specify the sender
      - Implicit: Receiver is told about the sender
    - Indirect addressing
      - Messages sent/received to/from ports/mailboxes (queues)
      - Allows for (one/many)-to-(one/many)
        - Many-to-one: Port (e.g. 80)
        - Others: Mailbox
  - Messages contain:
    - Type
    - Destination ID
    - Source ID (optional)
    - Message length
    - Control information
    - Contents
  - Messages can be retrieved FIFO, by priority, or by receiver choice
- Reader/Writer problem
  - n readers can read, 1 writer can write
  - but when the writer writes, no readers can read
  - Readers have priority: Solve with 2 semaphores
  - Writers have priortiy: Solve with 5 semaphores, is harder
  - Either readers or writers can have priority
    - Can solve with semaphores

### Ch 6: Concurrency: Deadlock and Starvation

- Joint progress diagram
  - Way to visualize how deadlocks can form
  - Each axis is progress along one process
  - Resource get/release represented as lines
  - Fatal region: where deadlock is inevitable / has already happened
- Deadlock
  - When two processes mutually block forever due to a conflict in resources.
  - Resource types
    - Reusable
      - Processors, I/O channels, memory
      - Deadlock happens when processes wait on resources in a cycle
    - Consumable
      - Interrupts, signals, messages, I/O buffer information
      - Deadlock happens when multiple processes block on receive/send calls.
- Resource allocation graph
  - Way to represent which processes are holding which resources
  - Resources are squares with dots = the number of resources available
  - Processes are circles that the dots point to
- Conditions for deadlock:
  - Possibility:
    - Mutual exclusion: Only one thing can access at a time
    - Hold and wait: Processes holding resources while waiting for others
    - No preemption: Processes cannot forcibly lose resources.
  - "Actually Happening":
    - Circular wait: Processes wait for resources in a cycle
- Deadlock Prevention: Static. Prevent one of the three Conditions. Surefire, but usually not good.
  - Mutual exclusion: usually not an option
  - Hold and wait: Allocate everything upfront. Often not possible, inefficient.
  - No preemption: Allow resources to be forcibly removed (triggered by process itself asking for more or another process asking for more). Sometimes doable.
  - Circular wait: Order resources, and force allocation in that order.
- Deadlock Avoidance: At runtime. Can use The Banker's Algorithm.
- The Banker's Algorithm:
  - By Dijkstra
  - Requires that:
    - Processes state maximum resource requirements up front
    - Independent processes
    - Fixed number of resources
    - No process exits while holding resources
  - Define:
    - n processes, m resources
    - m-vectors R (Resource), V (Available)
    - n×m-matrices C (Claim), A (Allocation)
    - C-A is amount of resources needed to ensure completion
    - R(i): Total amount of resource i
    - V(i): Available amount of resource i
    - C(i,j): Requirement of process i for resource j
    - A(i,j): Current allocation to process i of resource j
  - Safe state: At least one seqence of resource allocations does not result in a deadlock
  - To determine safety, repeatedly run a process to completion if possible and see if all processes can finish. Greedy works.
  - Practice this on paper!
- Deadlock Detection: 
  - Like the Banker's Algorithm but you're given C-A directly instead of having to compute it
  - Recovery
    - Abort them all. (most common solution)
    - Abort them one by one until the deadlock is fixed
    - Reverse time for deadlocked processes and restart them (retoast)
    - Preempt resources
- Dining philosopher's problem
  - Five plates, five forks. Philosophers need both forks to eat spaghetti.
  - Deadlock if each philosopher takes one fork.
  - Solutions:
    - Eating lock.
    - Limiting number of eating philosophers.
- UNIX concurrency
  - Pipes: FIFO circular buffer that allows reading and writing. Can be named or unnamed.
  - Message passing: msgsnd, msgrcv.
  - Shared memory: shm
  - Semaphores: generalized semaphores with four ops depending on `sem_op`
    - `sem_op` positive: like semSignal
    - `sem_op` == 0: block until semaphore == 0
    - `sem_op` negative until abs(semaphore value): adds `sem_op` to the semaphore value
    - `sem_op` really negative: block until semaphore increases
  - Signals (SIGKILL, SIGSEGV, SIGINT, SIGTERM etc)
- Linux concurrency
  - Includes SVR4
  - RT: Real-time signals
  - Atomic operations predefined, like `atomic_set` on type `atomic_t`
  - Spinlock: Polled thread lock
  - Barrier: Prevent reordering accesses
- Solaris thread synchronization
  - Includes SVR4
  - Four primitives:
    - Mutex locks
    - Semaphores
    - Readers/writer lock
    - Condition variables
- Windows 7 concurrency
  - Wait functions: threads block their own execution
  - Dispatcher objects: kill me now
- Android IPC
  - Binder: Lightweight RPC system
    - uses ioctl

### Ch 7: Memory management

- Memory management requirements (PLS RP)
  - Physical organization: Data can be moved between RAM and disk.
  - Logical organization: There are independent memory "modules" with independent R/W protection.
  - Sharing: Common data can be shared. (e.g. standard libraries)
  - Relocation: Data can be moved around physically.
  - Protection: Prevent segfaults dynamically.
- Address types
  - Physical address: Actual absolute location on memory device.
  - Logical address: Physical address is some function of it.
  - Relative address: Physical address is offset from it.
    - Adder and comparator used to translate and bound check
    - Base register and bounds register are relevant
- Types of fragmentation
  - **Internal fragmentation**: unused space within a block.
  - **External fragmentation**: unused space outside of blocks.
- Fixed partitioning
  - Fixed-sized memory blocks. Can have multiple fixed sizes.
  - Much internal fragmentation.
- Dynamic partitioning
  - Memory blocks just the right size for the process.
  - Much external fragmentation. Use **compaction** to fix temporarily.
  - Placement algorithms:
    - Best-fit: Choose smallest block possible
    - First-fit: Choose first block that fits
    - Next-fit: Choose first block that fits starting from last placement
  - Buddy system: Memory is a binary space partition
- Paging
  - Divide memory into equal fixed-sized page frames.
  - Assign a number of pages to each process.
  - Address translation:
    - Logical address = page ++ offset
    - Physical address = frame ++ offset
    - Page table is used to obtain frame from page
  - No external fragmentation, a bit of internal fragmentation
- Simple segmentation
  - Program is divided into dynamic-length segments.
  - No internal fragmentation. A bit of external fragmentation.
  - Address translation:
    - Logical address = segment number ++ offset
    - Physical address = physical start ++ offset
    - Segment table is used to obtain physical start from segment number
- Loading
  - Absolute loading
    - Always loads module to the same physical address
  - Relocatable loading
    - Compiler produces relative addresses.
    - Loader translates them to physical addresses.
  - Dynamic run-time loading
    - Defer calculation of physical addresses until run time
    - Done by hardware for efficiency
- Linking
  - Linkage editor: linker that produces a relocatable load module
  - Dynamic linker:
    - Load time dynamic linking: addresses resolved at load time
    - Run-time dynamic linking: at run time

### Ch 8: Virtual memory

- Virtual memory: Use disk to store chunks of memory
  - Unused memory is written to disk.
  - Now-needed memory is read from disk.
- Requires:
  - Logical addresses
  - Run-time address translation
- Allows program to be running without entire program in memory!
- **Page faults** are triggered when CPU tries to access nonresident data that block the process until data is loaded into memory
- **Resident set**: How much a process is actually using
- **Thrashing**: When the computer uses too much time swapping rather than execution instructions
- **Principle of locality**: Stuff you need in the future is close to stuff you needed in the past.
- Virtual memory paging
  - Page table bits
    - Present (P): Whether page is actually in main memory
    - Modify (M): Whether page has been changed since last loaded into main memory
  - Hierarchial page table
    - 4KB root page table (in memory)
    - --> 4MB user page table (on disk)
    - --> 4GB user address space
  - Inverted page table: Hash map from page number to PID, with chaining
  - Translation lookaside buffer
    - Hardware cache from page number to physical address
    - Uses an associative mapping (lots of brute force circuits)
  - Page size
    - Very small: Large number of pages is available and page fault rate is low
    - Medium: More page faults
    - Very large: Page covers the entire process and page fault rate is low
- Virtual memory segmentation
  - Segment table also needs Present and Modify bits.
  - Possibly other bits too for protection or sharing.
- Combined paging and segmentation
  - Segments built on top of pages
- Operating system decisions
  - Fetch policy: When are pages loaded?
    - Demand paging: Page loaded only when reference is made
    - Prepaging: Pages loaded in advance
  - Placement policy: Best/first/next fit (discussed earlier)
  - Replacement policy: Which page to replace?
    - Frame locking: Page marked as cannot be replaced
    - Basic algorithms
      - Optimal: Replace page that won't be used for the longest (requries precognition)
      - LRU: Replace page that hasn't been used for the longest
      - FIFO: Replace page that was loaded earliest
      - Clock: Approximate LRU using a use bit
        - When page is replaced, OS scans until it finds a frame with use bit 0. Otherwise sets it to 0.
      - Page buffering
        - Have free page list, modified page list
  - Resident set management:
    - How many page frames to give to each process?
    - Which pages should we even consider for replacement?
    - Fixed allocation:
      - Each process has fixed number of frames
    - Variable allocation:
      - Process can gain or lose page frames
    - Replacement scope
      - Local: Only chooses among resident pages of faulting process
      - Global: Considers all pages in memory
    - Fixed allocation, global scope is not possible
    - Page fault frequency algorithm
  - Cleaning policy
    - Demand cleaning: Page written out only when selected for replacement
    - Precleaning: Pages written out in batches
  - Load control
    - Don't thrash
    - Process suspension criteria:
      - Lowest priority
      - Faulting
      - Last activated
      - Smallest resident set
      - Largest process
      - Largest remaining execution window
- Unix and Solaris
  - Used to be variable partitioning, is now paged
  - Page table: one per process
  - Disk block descriptor: one for each page of a process
  - Page frame data table: describes each page frame
  - Swap-use table: one for each swap device
  - Two-handed clock replacement algorithm. Scanrate and handspread
- Linux
  - Three level page table structure
    - Page directory -> Page middle directory -> Page table -> Page frame
  - Page replacement: Split LRU
  - Memory allocation is complex, uses slab allocation
- Windows
  - Virtual address space:
    - 0x00000000 to 0x0000ffff: reserved to help catch null pointers
    - 0x00010000 to 0x7ffeffff: user address space
    - 0x7fff0000 to 0x7fffffff: guard page to check out of bounds
    - 0x80000000 to 0xffffffff: system address space, used by executive, kernel, HAL, drivers
  - Paging:
    - Three types of regions
      - Available: addresses not currently used by the process
      - Reserved: set aside for a process
      - Committed: committed
- Android
  - ASHMem: anonymous shared memory
  - Pmem: physically contiguous virtual memory
  - Low Memory Killer

### Ch 9: Uniprocessor scheduling

- Types of scheduling
  - Long-term: Decision to add to pool of processes
  - Medium-term: Decision to put process in main memory
  - Short-term: Decision to execute process
  - I/O: Decision of which process's I/O should be handled
- Short term scheduling criteria
  - User oriented, performance related
    - Turnaround time: time between process submission and completion
    - Response time: time between request submission and receiving response
    - Deadlines
  - User oriented, other
    - Predictability: Running time should have low variance
  - System oriented, performance related
    - Throughput: Maximize processes completed / time
    - Processor utilization: Maximize processor usage
  - System oriented, other
    - Fairness: No process should starve
    - Enforce priorities
    - Balance resources
- Decision modes
  - Preemptive: Can override current process
  - Non-preemptive: Does not override current process
- Selection function: picks next process to execute in short term scheduling
  - FCFS (First come first serve)
  - Round robin
  - SPN (Shortest process next)
  - SRT (Shortest remaining time)
  - HRRN (Highest response ratio next)
    - R = (w + s) / s, where w is time spent waiting for processor and s is expected service time
  - Feedback: Penalize long-running jobs
    - Multi-level feedback: n queues
    - Every time a process is preempted, demote it by one queue if possible
      - Can demote only if process has exceeded some number of time units (e.g. $2^n$)
    - To prevent starvation, can promote processes after a certain amount of waiting time
- Unix
  - One-second preemption

### Ch 10: Multiprocessor, multicore, and real-time scheduling

- Types of coupling
  - Loosely coupled - distributed systems
  - Functionally specialized - I/O module, GPUs
  - Tightly coupled - multiple cores

- The five types of synchronization granularity are:
  - Fine
  - Medium
  - Coarse
  - Very coarse
  - Independent

- The four types of thread scheduling are:
  - Load sharing: Global queue of ready threads
  - Gang scheduling: Related threads run on processes all at once
  - Dedicated processor assignment: All threads of a process run until complete
  - Dynamic scheduling: Number of threads of a process can change

- The three disadvantages of load sharing are:
  - Central queue needs mutual exclusion
  - Cache misses from "preemptive threads" switching processors
  - A single application's threads usually won't all be on the processor, which might matter

- The types of real time tasks are:
  - Soft real time -- Response time is an average. Not too important.
  - Hard real time -- Response time is a strict upper bound. Safety critical.
  - Aperiodic -- Deadline, start and finish time
  - Periodic -- Must run at least once per some period, or exactly some period apart

- The five requirements for a real-time system are: (DRURF)
  - Determinism -- Operations are performed at predetermined times
  - Responsiveness -- (Low) time to handle interrupts
  - User control -- Over task priority, type
  - Reliability -- Lack of failures
  - Fail-soft operation -- Graceful degradation in case of failure

- The kinds of real-time scheduling algorithm are:
  - Static table-driven
    - Statically analyze feasible schedules
    - Earliest-Deadline-First, usually
  - Static priority-driven preemptive
    - As above, but not scheduled (instead use priorities)
    - e.g. Rate Monotonic
  - Dynamic planning-based
    - Determine feasibility at run-time
    - Can reject tasks
  - Dynamic best effort
    - Try to meet all deadlines
    - Abort processes that miss deadline

- Deadline scheduling uses the following information about the process
  - Ready time -- when it can be run
  - Starting deadline
  - Completion deadline
  - Processing time
  - Resource requirements
  - Priority (hard vs. soft)
  - Subtask structure

- Rate monontonic scheduling
  - Used for periodic tasks
  - Lowest period task is highest priority
  - $C/T$ is fraction of usage required
  - Requires sum of fractions less than $n (2^{1/n} - 1) \to \ln(2)$
- Priority inversion
  - High priority task forced to wait on low-priority task
    - e.g. locked resource
  - But low-priority task never runs due to medium-priority task
  - Solutions:
    - Priority inheritance: give low priority task high priority when it has the resource
    - Priority ceiling: Give each resource a priority higher than that of any of its users

- Linux scheduling
  - 140 priority levels
    - 0-99 are real-time
    - 100-139 are not
  - `SCHED_FIFO`, `SCHED_RR`, `SCHED_OTHER`
    - First two are real-time
    - Priorities
    - RR does timeslicing within the same priority level
  - $O(1)$ scheduler
    - New scheduler for non-real-time tasks
    - Maintains number of tasks, priority bitmap for each processor
    - Schedule round-robin within highest nonempty priority
    - Time slices between 10-200ms

- UNIX SVR4 scheduling
  - 160 priority levels
    - top 60 realtime
    - next 40 kernel
    - last 60 user

- UNIX FreeBSD scheduling
  - 256 priority levels, split into five classes
    - top 64 for bottom-half kernel (interrupts)
    - next 64 for top-half kernel (rununtil blocked or done)
    - next 32 for real-time user
    - next 64 for time-sharing user
    - last 32 for idle user
  - interacivity scoring
    - run time / voluntary sleep time < threshold --> interactive
  - thread migration
    - processor caches are good
    - don't move threads by default
    - pull mechanism: idle processor steals a thread
    - push mechanism: equalize processors periodically

- Windows scheduling
  - Two priority classes
    - Real time: all threads have fixed priority
    - Variable priority: thread has initial priority, can be boosted temporarily
  - 15 or below never boosted to 16 or above
  - Soft affinity: Tries to assign thread to same processor it previously ran on
  - Hard affinity: Restrict thread to certain processors

### Ch 11: I/O Management 

- Three types of I/O devices
  - Human readable (e.g. displays, keyboard)
  - Machine readable (e.g. disks, sensors)
  - Communication (e.g. modems)
- Properties of I/O devices
  - Data rate
  - Application (what's it used for?)
  - Complexity of control (printers easy, disks hard)
  - Unit of transfer (stream vs. blocks)
  - Error conditions
- Techniques for performing I/O
  - Programmed I/O
  - Interrupt driven I/O
  - Direct memory access (D M A)
- Evolution of I/O function
  - Direct programmed control
  - Programmed I/O
  - Interrupt driven I/O
  - Direct memory access (I/O module <-> memory direct link)
  - I/O module has its own processor
  - I/O module has its own memory
- Design objectives
  - Efficiency: Interleave I/O and processing
  - Generality: Abstract away specifics of I/O device
- I/O organization model
  - Logical I/O: Deal with device as logical resource
  - Device I/O: Convert requested operations into I/O instructions, buffering
  - Scheduling and control: queue stuff, handle interrupts, interact with hardware
  - For file system, additional layers:
    - Directory management
    - File system
    - Physical organization
- I/O buffering
  - Block-oriented device
    - Information stored and transferred in fixed-size blocks
    - e.g. disks, USB keys
  - Stream-oriented device
    - I/O
    - e.g. keyboard, network
  - Types of buffering
    - Single buffering: one buffer
    - Double buffering / buffer swapping: two buffers, swap pointers
    - Circular buffering: Many buffers. Useful if there are bursts of I/O.
- Disk scheduling
  - Disks are 4 orders of magnitude slower than memory
  - Terms:
    - Seek time: Time to position the head on the track (circle)
    - Rotational delay: Time for beginning of sector to reach the head
    - Access time: Seek time + rotational delay
    - Transfer time: Time to transfer all data
      - `T = b / (rN)`
      - T: Transfer time
      - b: # bytes to transfer
      - N: # bytes on a track
      - r: rotation speed, RPS of disk
  - Scheduling policies:
    - Random scheduling: Bad. Useful as a benchmark
    - FIFO: Process in a queue. Essentially random
    - Priority: Usually requests from high priority are close together
    - LIFO: Process in a stack. Actually kinda good since last request is usually close
    - SSTF: Shortest Service Time First.
    - SCAN: Arm moves in one direction only, satisfying all requests as it moves
      - Reverse direction at end
    - LOOK: SCAN but reverses direction when there are no more requests in that direction
    - C-SCAN: Moves to beginning instead of reversing, reduces worst case
    - To prevent "arm stickiness":
      - N-step-SCAN: Process in batches of $N$. Large $N$ equivalent to SCAN.
      - FSCAN: Two queues. During scan of one queue, add new requests to other queue.
  - RAID:
    - 0: Striping. Nonredundant. High transfer rate.
    - 1: Mirroring. 2N disks.
      - Read requests handled by either copy
      - Write requests done in parallel
    - 2: Hamming code. N+m disks.
    - 3: Bit-interleaved parity. N+1 disks.
      - Can restore data if a single disk fails.
    - 4: Block-interleaved parity. N+1 disks.
    - 5: Block-interleaved distributed parity. N+1 disks.
      - Parity blocks distributed throughout drives
    - 6: Block-interleaved dual distributed parity. N+2 disks.
      - Two parity blocks for each block
      - Two disks can fail, data full recover
      - 30% drop in write performance, read comparable to RAID 5
- Disk cache
  - Cache disk blocks in main memory
  - Replacement policy: LRU best, LFU may be more appropriate
  - Frequency-based replacement
    - Blocks are a stack
    - Top part is "new section"
    - Rereferencing in new section does not increase access count
    - Replace lowest access count in old section
- UNIX SVR4 I/O
  - I/O devices are files
  - Buffer cache is disk cache
  - Separate buffering (character queue) for character-oriented devices
  - Unbuffered I/O using DMA
  - Different strategies for different devices
- Linux I/O
  - Similar to UNIX
    - Linux Elevator
      - Schedules disk using LOOK
      - Merges requests
    - Deadline scheduler:
      - Read requests more urgent than writes
      - Expiration time forces request to be handled FIFO instead of priority
    - Page cache for system files and virtual memory
    - Buffer cache for block I/O
      - Caches are good
- Windows I/O
  - Four components
    - Cache manager
    - Filesystem drivers
    - Network drivers
    - Hardware device drivers
  - Can be async or sync
  - Has software support for RAID 1 and RAID 5
  - BitLocker: Encrypts entire partition

### Ch 12: File Management

- Power words
  - Bit table
  - Disk allocation table
  - File directory
  - File management system
  - Pile
  - Record
  - Sequential file
  - Working directory

- Desired properties of a data collection
  - Long-term persistence
  - Sharing between processes
  - Structure, for organization
- Operations on files
  - Create, Delete, Open Close Read Write
- File structure terms
  - Field: Basic element of data
  - Record: Collection of related fields
  - File: Collection of similar records
  - Database: Collection of related data
- File management systems
  - Six requirements:
    - Each user can create/delete/read/write/modify files
    - Each user can access other users' files in a controlled way
    - Each user can control permissions on their own files
    - Each user can move data between files
    - Each user can back up and recover their files
    - Each user can access their files by name
- File organization systems
  - Device drivers: Communicate with devices
  - Basic file system, or Physical I/O: Blocks of data
  - Basic I/O supervisor: part of the OS, responsible for I/O init and term
  - Logical I/O: Deals with file records
  - Access method: Standard interface of file systems
  - Pile
    - Variable-length records with variable set of fields.
    - Chronological order
    - Bad seek time
  - Sequential file
    - Constant-length records with same set of fields
    - Key field: Identifies record
    - Better at searching
    - Bad seek time
  - Indexed sequential file
    - Index speeds up random access on the primary key
    - Overflow file
  - Indexed file
    - Multiple indexes for commonly searched fields
  - Direct / Hashed file
    - Hash primary key field to get address of record
- B-Trees
  - not on exam lol
- File directories
  - Tree-like node used to organize files
  - Information elements
    - Basic Information: File name, type, organization
    - Address Information: volume, start address, size used, size allocated
    - Access Control Info: Owner, access information, permitted actions
    - Usage Information: Date created, creator, atime, modified time, backup time, current usage
- File sharing
  - Access rights
    - None: User cannot even see that the file exists.
    - Knowledge: User can see the file exists.
    - Execution: User can run program, but cannot copy it.
    - Reading: User can read the file (and most of the time, copy it).
    - Appending: User can add data to the end
    - Updating: User can update the file's data.
    - Changing protection: User can change the file's access rights
    - Deletion: User can delete the file
  - Simultaneous access
    - Can lock entire file, or just updated records
    - Mutual Exclusion.
- Record blocking
  - Fixed blocking: Fixed-length records. Integer records per block.
  - Variable-length spanned blocking: Variable-length records are partitioned into blocks.
    - Some records must span two blocks.
  - Variable-length unspanned blocking: Variable-length records, but not partitioned into blocks.
    - Has wasted space at the end of blocks.
- Secondary storage management
  - File allocation issues
    - Allocation policy
      - Preallocation: Estimate maximum size of file, allocate it all up front
      - Dynamic allocation: Resize file when it gets too big
    - Portion size
      - Variable, large contiguous portions
        - First fit / Best fit / Nearest fit
      - Blocks
    - File allocation methods
      - Contiguous allocation
        - File create: Single contiguous set of blocks
        - Requires compaction
      - Chained allocation
        - Each block of a file points to the next block
      - Indexed allocation
        - Index block points to all blocks in file
        - The best
    - Disk allocation table can:
      - Bitmap
      - Chain free blocks
      - Indexing: free space is a file
      - Free block list: maintain list of ids for free blocks
    - Volume
      - Logical disk
- UNIX file management
  - Six types of files
    - Regular/ordinary -- data
    - Directory -- list of file names and pointers to inodes
    - Special -- map to physical devices
    - Named pipe -- for IPC
    - Link -- Another pointer to an existing file
    - Symlink -- Contains **name** of linked file
  - inode
    - "index node"
    - contains basically all information about the file
  - inode table
    - contains inodes of all files in file system
  - Multi-level file allocation
    - 12 direct data blocks
    - single, double, triple indirect layers
    - allows for fixed size inodes, large maximum file size
- Linux virtual file system
  - Uniform interface to whatever file system is used
  - Need to map system calls to specific file system
  - Three caches, all your husbands:
    - inode cache: recently visited inodes
    - directory cache: directory names and inode numbers (speeds up `ls`)
    - buffer cache: file contents
- no other OS case studies. thank mr goose

### A S I D E: Embedded Software

This is a fun little part about things that crash and burn.

- Embedded system market is 100x the size of the personal computer market.
- Smartphones are not embedded systems because you can play Pokemon Go on them.
- Properties of embedded systems
  - Tightly coupled to the physical world
  - Rich in extra-functional requirements
  - Heterogeneous, networked at extreme scale
  - Sociological and ethical requirements
  - Designed for debuggability
- BMW 745i has:
  - ~70 processors (53 8-bit, 7 16-bit, 11 32-bit)
  - 2M lines of code
  - Many operating systems
- Busy beaver grows real fast dude
- Digital thermometer: one button, but kid manages to break it
- Failures:
  - Ariane 5: Upgraded chips, kept software. Software used 16 bit numbers, 64 bit numbers
  - Mars Pathfinder: interplanetary software patch
  - Mars Climate Orbiter: $85M crash
  - Mars Polar Lander: $120M
  - Patriot Missile Defence System: Turn it on and off again.
  - USS Yorktown Smart Ship: Entered a zero, causing divide by zero
  - Oerlikon GDF-005
  - Qantas Flight 72
  - Boeing Dreamline 787
  - Pacemakers: Acceelerometer wrong
  - Therac-25: B e a m   T y p e
- But some stuff works:
  - cool nuke power plant in toronta
  - pacemaker baby
- A u t o n o m o u s   V e h i c l e s
  - UW MOOSE

### Ch 15: Security and stuff

- CIA
  - Confidentiality
  - Integrity
  - Availability
- Types of intruders
  - Masqueraders: pretend to be legit users
  - Misfeasors: misuse their privileges
  - Clandestine: users try to seize control and remove the logs
- Intrusion detection system (IDS)
  - System that analyzes system events to identify anomalies.
  - Design goals
    - Latency until detection
    - False positive and false negative rate
    - Low resource consumption
  - Elements
    - Sensors
    - Analyzers
    - User interface
- Intrusion protection system (IPS): actively prevent intrusion
- Authentication
  - Something only the user:
    - Knows: password
    - Possesses: yubikey
    - Is (static biometrics): fingerprints, retina
    - Can do (dynamic biometrics): secret handshake, mouse movement patterns, typing pattern
- Access control policies
  - Discretionary: Based on identity. Rights can be transferred.
  - Mandatory: Based on identity. Rights cannot be transferred.
  - Role-based: Based on roles and rules for roles.
