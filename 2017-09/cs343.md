# CS 343: Concurrency

Professor: Peter Buhr

## 1. Advanced control flow

Omitted.

## 2. Exceptions

- [Activation]: [Invoking a routine.]

- Calls can be static or dynamic
- Returns can also be static or dynamic
- Static propagation
  - Sequel
- Dynamic propagation
  - Termination
  - Resumption `_Resume`

- [Execution]: Language unit in which an exception can be raised.

- [Source execution]: The execution raising an exception. The throw.

- [Faulting execution]: Execution that handles the raised exception. The catch.

- [Local exception]: Exception caught by the same execution.

- [Non-local exception]: Execution delievered to a different faulting execution

- [Unguarded block]: Block with no exception handlers

- [Termination]: Stack is unwound. Control cannot return to the raise point.

- [Resumption]: Stack is not unwound. Control returns to the raise point.

## 3. Coroutine

- Coroutine state consists of execution: [location, state, status].

- State:
  - Execution location
  - Exeuction state (each coroutine has its own stack)
  - Execution status (active / inactive / terminated)

- A Life With N Stacks
- Semi-coroutine: Asymmetrical.
- Full-coroutine: Symmetrical.
- Linearization: Making loops flat.

- [Starter] coroutine: Does the first resume.

- Pull coroutine: Generates things in next().
- Push coroutine: Accepts things in next().
- Leverage the coroutine zen.
- Exception handling: `_Throw`, `_Suspend ... _At`, `_Catch`, `_CatchResume UnhandledException`
- For assignment: `_Enable` in `main()`.

## 4. µC++ EHM

Omitted.

## 5. Concurrency

- Things that are things:
  - Thread: Execution path
  - Process: Program component with a thread
  - Task: Reduced process. Lightweight process

- Thread states: new, ready, running, blocked, halted

- CPUs run kernel threads run user threads
- Speedup is typically sublinear or (badly) nonlinear
- Amdahl's law: SC = 1 / ((1 - P) + P/C)

- Concurrency in µC++:
  - Include `<uCobegin.h>`
  - COBEGIN BEGIN END ... BEGIN END COEND
    - Can represent some lattices
  - auto x = START, WAIT(x)
  - COFOR(var, 0, 10) loops for row from 0 to 9
  - `_Task` objects

- Mutual Exclusion Game
  - Rules:
    - 1. Safety: Only one thread in something's critical section.
    - 2. Threads may run at any speed, in any order.
    - 3. Threads may not entering/leaving a critical section cannot prevent
         other threads from entering it.
    - 4. Liveness: No indefinite postponement / livelock.
    - 5. No starvation: Threads that have started must eventually enter CS.

- Software solutions to mutual exclusion
  - 1. Lock. Breaks rule 1.
  - 2. Alternation. Breaks rule 3.
  - 3. Declare Intent. Breaks rule 4.
  - 4. Retract Intent. Breaks rule 4.
  - 5. Prioritized Retract Intent. Breaks rule 5.
  - 6. Dekker's algorithm. Not RW-safe (non-atomic writes)
    - Hesselink: RW-safe version.
    - Unbounded overtaking: Race loser retracts intent
  - 7. Peterson's algorithm. Not RW-safe
    - Bounded overtaking: Race loser does not retract intent
      - Thread exiting critical section does not immediately re-enter.
  - 8. n-thread prioritized entry. Breaks rule 5.
  - 9. n-thread bakery.
  - 10. Tournament. Binary tree of Dekkers or Petersons.
  - 11. Arbiter. Task controls entry.

- Hardware solutions
  - 1. Test/set instruction: Attempts to set value of lock. Returns success if actually changed.
  - 2. Swap instruction: Atomic exchange of values.
  - 3. Fetch and increment: Increments a value and returns the original value.

## 6. Locks.

- Two types: spinning and blocking.

- Spinning:
  - No yield
  - Yield: Yields after a single failed check.

- Blocking: Must cooperate
  - Synchronization
    - Condition
    - Barrier
  - Semaphore
    - Binary
    - Counting
  - Mutex
    - Owner
  - (Many others)

- Mutex lock
  - Type of blocking lock
  - Single acquisition: Acquirer cannot acquire lock again
  - Multiple acquisition: Acquirer can acquire lock multiple times
  - May require only one release, or as many releases as acquires
  - Implementation details:
    - Don't block when holding the lock: Release lock before blocking
    - Race between blocking and unblocking tasks.
    - Magic: yieldNoSchedule( lock );
  - Barging: Acquiring tasks can barge ahead of the released task.
  - Barging avoidance: Hold inUse flag between releasing and unblocking task
  - Barging prevention: Hold lock between releasing and unblocking task
  - In uC++: uOwnerLock

- Synchronization lock
  - To block tasks waiting for synchronization.
  - External locking: External lock protects task list. Very dangerous
  - Internal locking: Lock is part of state.
  - in uC++: uCondLock

- Stream locks: sync locks for I/O streams in particular
  - In uC++: osacquire( cout )

- Barrier
  - Does not proceed until specified number of tasks block on the barrier
  - In uC++: uBarrier

- Binary semaphore
  - P: acquire (set inUse to true)
  - V: release (set inUse to false)

- Counting semaphore:
  - P: decrement
  - V: increment
  - Has an initial value (the "maximum concurrency")
  - in uC++: uSemaphore
    - has TryP: returns success

- Precedence graph
  - DAG of dependencies
  - To solve with semaphores, assign each code segment a semaphore, V after
    it's done, P before dependencies, some more V's to ensure it actually works
- Buffering
  - Unbounded buffer: Buffer is of unbounded length.
  - Bounded buffer: Buffer has some max length.
    - Producers have to wait if the buffer is full.
    - Consumers have to wait if the buffer is empty.

- Lock techniques
  - Split binary semaphore: Collection of semaphores where at most one is 1.
  - Baton passing: Using split binary semaphores to "pass a baton" around
    - Nobody can move in the entry/exit code unless you have the baton.
    - Once the baton is released, you cannot read or write variables in the
      entry/exit code.

- Readers and Writers problem with baton passing.
  - Seven Solutions, All My Husbands
  - Solution 1:
    - Typical baton-passing solution.
    - Benches: Arrivers, readers, writers.
    - HOLD THE FUCK UP, there STARVING WRITERS in the house.
  - Solution 2:
    - Make readers wait if there are any waiting writers.
    - Writers favour writers.
    - Readers starve instead of writers.
  - Solution 3:
    - Alternate readers and writers. (by Dekker)
    - Eliminates starvation.
    - Causes staleness/freshness issues
  - Solution 4:
    - Service readers and writers in temporal FIFO order.
      - Use the same semaphore
    - Use shadow queue to keep track of type of task
  - Solution 5:
    - Reader/writer bench, writer chair.
  - Solution 6:
    - Turn off time slicing
    - Or: Use ticket (inefficient)
    - Or: Use private semaphore
  - Solution 7:
    - Ad-hoc solution

- On the assignment, Barrier use is very simple.
  - Can confirm.

- Who's talking? Can you shut up? 'Cause I'm talking.
- Oh yeah, just a little bit of documentation and I'm finished.
- I'm in the Bomber! You're writing if statements!
- Use the Zen of the Counting Semaphorek.
- Producer/consumer: The produce and consumer critical sections are DEPENDENT.
  (TW: Midterm)
- I have flogged this example into thin soup.
- That's horrifying. Panic is the only word.

- Professional party-goer:
  - Around 2 o'clock, you look around; if the party is winding down, gtfo or
    you'll have to clean up

- Our assignments always start with a performance test because it's really hard
  to judge performance in concurrency.

## 8. Indirect communication

- Transactional memory looks like a bust
- Can the language help us with concurrency?
- Compilers are great for grinding the low level stuff.

- 8.1: Critical regions
  - Object oriented programming was done by the Norwegians
  - SIMULA 67
    - COROUTINES were there. Boy did they get it right.
  - `VAR v: SHARED INTEGER MutexLock v_lock;`
    - "v is a SHARED INTEGER. It has CONCURRENCY."
  - `REGION v DO // critical section END REGION`.
    - Acquires mutual exclusion on v.
  - In uC++: `_Task` says you're writing a concurrent program.

- 8.2: Conditional critical regions
  - `REGION v DO AWAIT condition ... END REGION`
    - Waits for a condition to be true as well as taking the lock

- 8.3: Monitor
  - Norwegian object-oriented + concurrent love bb.
  - Magically provides serialized modification.
  - `_Mutex` members: Only one thread can be in any of them at once.
  - `_Nomutex`: Explicitly disable mutex

- 8.4: Scheduling
  - `_Accept`: Requires a call to the given method before execution continues
  - `uCondition`: queue of waiting tasks. .wait(), .signal(), .signalBlock()

- 8.5: Readers/Writers problem
  - Can be solved with monitors very nicely
  - [Nested monitor problem]:
    - Acquire monitor X
    - Call monitor Y
    - Wait on condition in Y
    - X's monitor lock is not released, causing potential deadlock
    - No known solution

- 8.6: Condition, signal, wait vs. counting semaphore, V, P
  - Can simulate counting semaphore with a monitor

- 8.7: Monitor types
  - [Explicit scheduling]:
    - [Internal scheduling]:
      - Callers block on condition locks, signals unblock them
    - [External scheduling]:
      - Using `_Accept` to block the active task on the acceptor stack
  - [Implicit scheduling]: 
    - Task waits in / exits from a mutex member and a new task is selected from
      the acceptor/signalled stack
    - Use `waitUntil`
  - [Immediate-return signal]: Signaller exits immediately
    - Not as powerful, can't handle dating service

- 8.8: Java monitor
  - `synchronized` makes members `_Mutex`
  - All classes have a single condition variable
  - `wait()`, `notify()`, and `notifyAll()` used to manipulate it

- [Spurious wakeup]:
  - Have to put your Java wait() in a loop.
  - A conspiracy. Fake news. It doesn't exist.

- Cannot build condition variables in Java because it deadlocks at
  condition.Wait() since monitor's mutual exclusion lock is not released.

## 7. Concurrent errors

- Race condition: Missing synchronization or mutual exclusion
- 7.2.1: Livelock.
  - Poor scheduling in entry protocol.
  - "You go first" indefinitely. Oracle with cardboard test.
- 7.2.2: Starvation.
  - Someone never runs. No long term fairness.
  - Long-term rare. Short-term starvation is still a problem.
- 7.2.3: Deadlock.
  - Processes waiting for an event that will never occur.
- 7.2.3.1: Synchronization deadlock.
  - Failure in cooperation. Blocked task never unblocked.
- 7.2.3.2: Mutual exclusion deadlock.
  - Indefinite failure to acquire a resource.

- Oracle with cardboard test: if you can put cardboard in front of someone's
  eyes, and that fixes the problem, then it's a livelock. Otherwise, it's a
  deadlock. So some students say weeping angels is deadlock because of
  FEELINGS, not REALINGS.

- Five deadlock conditions:
  - 1. Mutual exclusion: A CONCRETE shared resource requires it.
  - 2. Hold and wait: A process holds the resource while waiting for access to a resource held by another resource.
  - 3. No preemption: Resource never forcibly released.
  - 4. Circular wait.
  - 5. The previous four must occur SIMULTANEOUSLY.

- 7.3: Deadlock prevention.

- 7.3.1: Synchronization deadlock prevention.
  - Just have no synchronization / communication.

- 7.3.2: Mutual exclusion deadlock prevention.
  - No mutual exclusion: Usually not possible
  - No hold and wait: Do not give resource until all resources can be given.
    - Starvation possible
  - Allow preemption: Cannot apply statically.
  - No circular wait: Use ordered resources.
  - Prevent simultaneous occurrence: Show that the previous 4 cannot occur
    simultaneously.

- 7.4: Deadlock avoidance
  - Monitor locks and resources and detect potential deadlocks.
  - 7.4.1: Banker's algorithm
    - We know this!
  - 7.4.2: Allocation graphs.
    - Create bipartite graph of resources and tasks.
    - No cycles means no deadlocks
    - Cycle means potential deadlock; may be fixable if resources have multiple
      instances

- 7.5: Detection and recovery
  - Kill deadlocked tasks

- 7.6: Which method to choose?
  - Most people don't do anything (Gates, Jobs)
  - Only ordered resource policy has been found to be practical IRL

## 9. Direct communication

- One task can CALL another task.
- A Task is a Cormonitor with its own thread.

- 9.2.1: External scheduling: Use `_Accept`.
- 9.2.2: Internal scheduling: wait and signal on `uCondition`s.
  - May need to use `signalBlock` since task thread has priority over calling
    threads.

- 9.3: Increasing concurrency
  - Client: caller. Server: callee.

- 9.3.1: Server-side communication.
- 9.3.1.1: Internal buffer.
- 9.3.1.2: Administrator.
  - Server that manages multiple clients and worker tasks.
  - Does little real work.
  - The administrator never calls anyone, since that may block the admin.
  - async calling: "a thing people invent for their language that interface
    with an Administrator"

- 9.3.2: Client-side communication.
- 9.3.2.1: Returning values: is hard.
- 9.3.2.2: Tickets: Are hard. Error prone. Forgery possible.
- 9.3.2.3: Call-back routine: Is good.
- 9.3.2.4: Future: Is quite good.
  - Future is returned immediately by call to server.
  - When the client tries to use the future, it blocks until the result is
    available.
  - `Future_ESM`: Wicked complicated, sophisticated. Allocated and deallocated
    by client.
    - not on exam !!
  - `Future_ISM`: Simpler, automatically allocates and frees storage.
  - `Future_ISM` can also be a future pointer.
    - e.g. can point variably to watcard / giftcard
  - Futures can be selected: `_Select ( f1 || f2 && f3 )`
  - Can also: `_Select( f1 ) or (_Select( f2 ) and _Select( f3 ))`
    - This blocks until either f1 or (f2 and f3) is done
  - Assignment is very simple. Complicated futures means you're way off into
    the pasture.
  - Use the simplest select statement on the planet.

## 10. Optimization

- Three Forms of Optimization:
  - [Reordering]: change order of code and/or data
  - [Eliding]: remove unnecessary code, data
  - [Replication]: Duplicate processors, memory, data, code

- 10.1: Sequential optimizations
  - [Data dependency]: Cannot reorder if same variable is written.
  - [Control dependency]: One line determines if another line is executed.
  - Optimizations:
    - 1. Reorder disjoint operations
    - 2. Elide unnecessary operations
      - e.g. x=0; x=3;
      - e.g. terminating loop with no body
      - e.g. tail recursion to loop
    - 3. Execute in parallel with multiple functional units

- 10.2: Memory hierarchy. Cache is a thing.
- 10.2.1: Cache review
  - [Cache line]: Chunk of 32/64/128 bytes that is cached as a unit.
- 10.2.2: Cache coherence. Caches have multiple levels.
  - [Cache coherence]: Hardware protocol that ensures update of duplicate data.
  - [Cache consistency]: When the processor sees the update.
    - Eager: Data changes appear instantaneous, by waiting for ack from all
      cores. Complex, expensive.
    - Lazy: Reader can see own write before ack. Concurrent programs can read
      stale data.
    - [Cache thrashing]: Updated value bounces from one cache to the next
    - [False sharing]: Inadvertent cache thrashing from shared cache line

- 10.3: Concurrent optimizations.
- 10.3.1: Disjoint reordering
  - RxRy allows RyRx: No problems
  - WxRy allows RyWx: [Dekker entry protocol] screws up
  - RxWy allows WyRx: [Synchronization flags] screw up
  - WxWy allows WyWx: [Sync flags, Peterson's entry protocol] screw up
- 10.3.2: Eliding
  - Can cause problems if flag is set by other task
  - Can cause problems if sleeps are elided
- 10.3.3: Replication
  - Double-check locking: Check condition before and after taking a lock to
    initialize some resource

- 10.4: Memory model
  - In order of increasing yoloness:
  - AT: [Atomic consistent]. [No relaxation, eager cache update].
  - SC: [Sequential consistency]. [Adds lazy cache update].
  - TSO: [Total store order]. [Adds W→R relaxation].
  - PSO: [Partial store order]. [Adds R→W relaxation].
  - WO: [Weak order]. [Adds W→W relaxation].
  - RC: Release consistency.

- 10.5: Preventing optimization problems.
  - [Race free] code has no races thanks to synchronization and mutual
    exclusion.
  - Two general approaches:
    - ad hoc: muh manual pragmas and mfences. often optimal, but not portable
    - formal: memory model; baroque, suboptimal

## 11. Other approaches

- 11.1: Atomic data structure
  - Critical sections performed without the need for ownership
  - Not really lock-free, since there's actually a spinlock
  - wait free: Guarantees individual progress
- 11.1.1: Compare and assign
  - Atomic instruction that compares and assigns
- 11.1.2: Lock-free stack
  - Stack that uses CAA to do push/pop lock-free style
- 11.1.3: ABA problem
  - top = A → B → C
  - Case breaks in very rare case
- 11.1.4: Hardware fix
  - Probabilistic solution: CAVD instruction.

- 11.2: Exotic atomic instruction
  - VAX has atomic instructions to insert/remove from doubly linked list
  - MIPS has LL (load locked) and SC (store conditional)
    - LL: Loads value from memory and set a hardware reservation on that memory
    - SC: Stores value only if reservation wasn't interrupt/except/written
  - Transactional memory:
    - SPECULATE: Start speculative region, clear zero flag
    - LOCK: MOVs indicate atomic access location
    - COMMIT: End speculative region, either commit or rollback
    - Does not have ABA problem
  - STM: Software transactional memory
    - Bookkeeping: Significant performance degradation
    - Lock insertion: Complex

- Class skipped above and started here because time
- All of the things we've learned in uC++ appear elsewhere!

- 11.3: General purpose GPU (GPGPU)
  - GPU is a [co]processor
  - GPU is SIMD (Single Instruction Multiple Data) -- Mmuh shaders
  - GPU structure:
    - kernel manages blocks contain wraps synchronize threads
    - kernel: manages multiple blocks
    - block: executes the same code
    - warp: synchronizes execution
    - thread: computes value
  - XMMS instructions:
    - Intel vector instructions, blazing fast
    - compilers have only recently started to use

- 11.4: Concurrency languages
  - 11.4.1: [Ada]
    - Semi-used. Lots of use in government contracts.
    - Used to be very good. Then people kept shoveling random stuff into it.
      Like C++ today.
    - Ada 95 has restricted automatic signal monitors.
    - Source of uC++'s accept statement, select, or.
    - Allowed callers to requeue, which provides magical internal scheduling.
    - Couldn't figure out OOP.
  - 11.4.2: [SR, Concurrent C++]
    - Didn't have condition variables or requeue, but DID have external
      scheduling and accept
    - `accept` statement could take a `when` clause
    - wasn't enough, so they added a `by` clause
  - 11.4.3: [Java]
    - synchronized methods
    - Thread implements Runnable
    - largely inspired by Modula-3.
    - Thread is like uC++'s uBaseTask
  - 11.4.4: [Go]
    - `goroutines`: non-OO lightweight threads
      - it's cute!
    - communication using channels passed into the goroutines
      - channels are just buffers
    - `select` is just uC++ `_Accept`
  - 11.4.5: [C++11]
    - it's horrible!
    - thread class has `join`, `joinable`, `detach`
    - thread class is initialized with a function that is the thread
    - go is non-OO; C++11 wraps functors (callables) in a thread object
    - threads must be explicitly `.join`'d -- not RAII
    - `detach`'d threads maybe die in the shrubbery
    - `mutex` class and `condition_variable` class; however they are barging!!
    - `future` is a thing!
    - atomics are also a thing

- 11.4: Concurrency models

- 11.4.1: [Actors]
  - THEY'RE BIG. Old idea, but became a hot topic.
  - Scala is a super super souped up Java. Akka gives you actors.
  - Actors are administrators with mailboxes. They DON'T have their own thread.
  - A worker pool runs the actors.
  - Communication is complex.
  - uC++ has actors (`_Actor`, `uActor`) -- not as sophisticated as Akka but 15x faster

- 11.4.2: [Linda]
  - (In class) Let's skip Linda
  - Based on multiset tuple space
  - Three operations for accessing the tuple space:
    - read: Reads a tuple
    - in: Identical to read, but removes the matching tuple
    - out: Writes a tuple

- 11.4.3: [OpenMP]
  - Very simple way to do concurrency
  - `#pragma omp section`

- 11.5: Libraries
  - 11.5.1: [java.util.concurrent]
    - Brings condition locks and things to Java.
    - By Doug Lee
    - He's a nice person, but he believes in spurious wakeup!
    - Cannot mix this with the synchronized garbage
    - uC++ also has executors. `uExecutor` is just a little administrator.
  - 11.5.2: [Pthreads]
    - OS level threading library, usually for C
    - Not type safe
    - Internal scheduling has barging
    - Write your own constructors and destructors

- Cforall is fun stuff
- I've made you concurrently dangerous.
  - But, you need more experience before you write Airbus A380 code.
