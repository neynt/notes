# CS 370: Numerical Computation

Professor: George Labahn

## Floating point arithmetic

A floating point number system F(b, t, L, U) contains:

- Zero
- ± 0.b₁b₂ ... b\_t × beta^d, where b₁ ≠ 0, b's between 0 and b, L ≤ d ≤ U.

So F(2, 24, -126, 127) is single precision, and F(2, 53, -1022, 1023) is double precision.

Computers approximate real numbers using floating point numbers. This approximation can lead to surprisingly large errors:

- In 5-digit arithmetic, e^-5.5 =
  - 0.0026363 if you use 1 - x + x^2/2 - x^3/3!
  - 0.0040868 if you use (1 + x + x^2/2 + x^3/3!)^-1
- In 4-digit arithmetic, one of the solutions to x^2 + 62.1x + 1 can be either -0.0200 or -0.0161.

### Analyzing errors

Let $$fl(x)$$ be the floating point representative of $$x$$ (i.e. $$x$$ truncated to $$t$$ digits in base $$\beta$$). Then, the relative error is

$$
\frac{fl(x) - x}{x}
$$

and the magnitude of relative error is at most

$$
\begin{eqnarray}
&&  \left| \frac{fl(x) - x}{x} \right| \\
&=& \frac{0.0\cdots 0x_{t+1}\cdots \times \beta^{d}}{0.x_1\cdots x_{t+1} \times \beta^{d}} \\
&=& \frac{0.x_{t+1}x_{t+2}\cdots}{x_1.x_{2}x_{3}\cdots} \cdot \frac{\beta^{-t}}{\beta^{-1}} \\
&\leq& \beta^{1-t}
\end{eqnarray}
$$

For rounding, it is $$ \beta^{1-t} / 2 $$.

Sometimes, it can be useful to write $$fl(x) = x(1+\delta), \delta < \varepsilon$$. Then,

$$
x \oplus y = fl(fl(x) + fl(y))
$$

A natural question to ask is: what is the relative error for addition? We can analyze as follows.

$$
\begin{eqnarray}
&   & \left| \frac{(x+y) - (x \oplus y)}{x + y} \right| \\
& = & \left| \frac{x+y - fl(fl(x) + fl(y))}{x+y} \right| \\
& = & \left| \frac{\delta_1 + \delta_2 x + \delta_3 x + \delta_2 y + \delta_1 \delta_3 x + \delta_2 \delta_3 y}{x + y} \right|, |\delta_i| < \varepsilon \\
&\leq& \left| \frac{(|x| + |y|)(2\varepsilon + \varepsilon^2)}{|x+y|} \right|
\end{eqnarray}
$$

Note that if $$x$$ and $$y$$ have the same sign, then the relative error of addition $$\leq 2\varepsilon + \varepsilon^2$$. But if they have different sign, and are close in magnitude, relative error is potentially huge, because all the important digits are discarded. This is **catastrophic cancelling**.

### Error explosions

Suppose we wanted to compute

$$
I_n = \int_{0}^{1} \frac{x^n}{x+\alpha} dx, n \in \mathbb{N}
$$

using the following recurrence

$$
\begin{eqnarray}
I_0 & = & \ln \left( \frac{1+\alpha}{\alpha} \right)
I_{n+1} & = & \frac{1}{n+1} - \alpha I_n
\end{eqnarray}
$$

On a computer, we get that for $$\alpha=0.5$$, $$I_100 = 0.00664$$, but for $$\alpha=2.0$$, $$I_100 = 2.1\times 10^22$$. Note that the second one cannot possibly be correct since $$\frac{x^n}{x + \alpha}$$ should stay under $$1$$.

To analyze this error, let

$$
e_n = I_0^{ex} - I_n^{app}
$$

where $$I^{ex}$$ is exact and $$I^{app}$$ is the numerical approximation. Notice that

$$
\begin{eqnarray}
e_{n+1} & = & I_{n+1}^{ex} - I_{n+1}^{app} \\
        & = & \left( \frac{1}{n+1} - \alpha I_n^{ex} \right) - \left( \frac{1}{n+1} - \alpha I_n^{app} \right) \\
        & = & -\alpha (I_n^{ex} - I_n^{app}) \\
        & = & -\alpha e_n \\
        & = & (-\alpha)^{n+1} e_0
\end{eqnarray}
$$

So the error will explode for $$ |\alpha| > 1 $$.

The solution to this is surprising: if $$ |\alpha| > 1 $$, work backwards. Assume that $$ I_{200} = 1 $$ and use $$ I_n = \frac{1}{\alpha (n+1)} - \frac{1}{\alpha} I_{n+1} $$. Although the "error" on $$ I_{200} $$ is huge since it was just a guess, it will quickly dwindle to nothing as you compute successive terms.

## Interpolation

Suppose that we are given $$n$$ points $$(x_1, y_1), \cdots, (x_N, y_N)$$ with $$x_i < x_{i+1}$$ and we wish to draw a "nice" curve that passes through all of them. How do?

### Polynomial interpolation

One way is to use a polynomial of degree $$<N$$. To do these, we set up a system of equations

$$
\begin{eqnarray}
c_1 + c_2 x_1 + \cdots + c_n x_1^{n-1} & = & y_1 \\
\vdots \\
c_1 + c_2 x_n + \cdots + c_n x_n^{n-1} & = & y_n
\end{eqnarray}
$$

equivalent to the equation

$$
\begin{bmatrix}
1 & x_1 & \cdots & x_1^{n-1} \\
\vdots & \vdots & \ddots & \vdots \\
1 & x_n & \cdots & x_n^{n-1}
\end{bmatrix}
\begin{bmatrix}
c_1 \\ \vdots \\ c_n
\end{bmatrix}
=
\begin{bmatrix}
y_1 \\ \vdots \\ y_n
\end{bmatrix}
$$

The big matrix is also called the Vandermonde matrix (V), so this can be written as

$$
V \vec{c} = \vec{y}
$$

Notice that since this matrix is invertible (its determinant $$\neq 0$$), it has a unique solution.

You can also use the **Lagrange form** of the interpolating polynomial:

$$
p(x) = a_1 L_1(x) + \cdots + a_n L_n(x)
$$

where

$$
L_i(x) = \prod_{j \neq i} (x - x_j) / \prod_{j \neq i} (x_i - x_j)
$$

### Hermite interpolation

Given points $$(x_L,y_L)$$, $$(x_R,y_R)$$ and slopes $$s_L, s_R$$, find a polynomial $$s(x)$$ of degree $$<4$$ such that $$s(x_L)=y_L$$, $$s'(x_L)=s_L$$, etc.

Write the equation as

$$
s(x) = c_1 + c_2(x - x_L) + c_3(x - x_L)^2 + c_4(x - x_L)^3
$$

After plugging in values, we obtaining a system of linear equations that we can put in a matrix. (Let $$\Delta x = x_R - x_L$$)

$$
\begin{bmatrix}
1 & 0 & 0 & 0 & y_L \\
0 & 1 & 0 & 0 & s_L \\
1 & \Delta x & \Delta x^2 & \Delta x^3 & y_R \\
0 & 1 & 2 \Delta x & 3 \Delta x^2 & s_R
\end{bmatrix}
$$

Solving, we get

$$
\begin{eqnarray}
c_1 & = & y_L \\
c_2 & = & s_L \\
c_3 & = & \frac{3y_L^\prime - s_R - 2s_L}{\Delta x} \\
c_4 & = & \frac{-2y_L^\prime + s_R + s_L}{\Delta x^2}
\end{eqnarray}
$$

where $$y_L^\prime = \frac{y_R - y_L}{x_R - x_L}$$.

### Cubic splines

A cubic spline $$s(x)$$ interpolates between $$N$$ points $${(x_i,y_i)}$$ using a piecewise function with $$N-1$$ parts and the following properties:

1. Each part is a polynomial of degree $$\leq 3$$
2. $$s(x)$$ passes through all the points
3. $$s'(x)$$ is continuous in $$[x_1, x_N}$$
4. $$s''(x)$$ too
5. Boundary conditions

We have $$N-1$$ polynomials of the form $$S_i(x) = a_i + b_i(x-x_i) + c_i(x-x_i)^2 + d_i(x-x_i)^3$$ for $$i=1,\cdots,N-1$$, so we have $$4N-4$$ unknowns.

From condition (2), we get $$2N-2$$ equations from the set endpoints.

From conditions (3) and (4), we get another $$2N-4$$ equations from $$s'$$ and $$s''$$ needing to be equal at the $$2N-4$$ interior points.

So we have $$4N-6$$ equations. This is not enough, so we add boundary conditions of our choosing.

1. Natural spline: $$s''(x_1) = s''(x_) = 0$$. Spline is straight outside of points.
2. Clamped spline: $$s'(x_1) = s_1$$, $$s'(x_N) = s_N$$ for some $$s_1$$, $$s_N$$. Forced derivatives.
3. Periodic spline: $$s'(x_1) = s'(x_N)$$, $$s''(x_1) = s''(x_N)$$.
4. Not-a-knot: $$s'''$$ continuous at $$x_2$$ and $$x_{N-1}$$. Note that this makes two cubics the same at each end. This is the Matlab default.

To compute the actual spline, we could set up a linear system of $$4N-4$$ unknowns and solve the matrix. But this takes $$O(N^3)$$ time, so let's not do that.

Instead, we find only the unknown derivatives $$s_1,\cdots,s_N$$. This is only $$N$$ unknowns, but if we find them all, we can find all coefficients from Hermite interpolation:

$$
\begin{eqnarray}
a_i & = & y_i \\
b_i & = & s_i \\
c_i & = & \frac{3y^{\prime}_{i} - 2s_i - s_{i+1}}{\Delta x_i} \\
d_i & = & \frac{s_i + s_{i+1} - 2y^{\prime}_{i}}{\Delta x_i^2}
\end{eqnarray}
$$

where $$\Delta x_i = x_{i+1} - x_i$$, $$y_{i}^\prime = \frac{y_{i+1} - y_i}{\Delta x_i}$$.

We obtain two equations from boundary conditions and $$N-2$$ equations from $$S''_{i-1}(x_i) = S''_i(x_i)$$ for $$i=2,\cdots,N-1$$. This system can be solved in linear time, since every entry in the matrix that is not within distance $$1$$ of the diagonal is $$0$$.
