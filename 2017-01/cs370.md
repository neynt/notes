# CS 370: Numerical Computation

Professor: George Labahn

## Floating point arithmetic

A floating point number system F(b, t, L, U) contains:

- Zero
- ± 0.b₁b₂ ... b\_t × beta^d, where b₁ ≠ 0, b's between 0 and b, L ≤ d ≤ U.

So F(2, 24, -126, 127) is single precision, and F(2, 53, -1022, 1023) is double precision.

Computers approximate real numbers using floating point numbers. This approximation can lead to surprisingly large errors:

- In 5-digit arithmetic, e^-5.5 =
  - 0.0026363 if you use 1 - x + x^2/2 - x^3/3!
  - 0.0040868 if you use (1 + x + x^2/2 + x^3/3!)^-1
- In 4-digit arithmetic, one of the solutions to x^2 + 62.1x + 1 can be either -0.0200 or -0.0161.

### Analyzing errors

Let $$fl(x)$$ be the floating point representative of $$x$$ (i.e. $$x$$ truncated to $$t$$ digits in base $$\beta$$). Then, the relative error is

$$
\frac{fl(x) - x}{x}
$$

and the magnitude of relative error is at most

$$
\begin{eqnarray}
&&  \left| \frac{fl(x) - x}{x} \right| \\
&=& \frac{0.0\cdots 0x_{t+1}\cdots \times \beta^{d}}{0.x_1\cdots x_{t+1} \times \beta^{d}} \\
&=& \frac{0.x_{t+1}x_{t+2}\cdots}{x_1.x_{2}x_{3}\cdots} \cdot \frac{\beta^{-t}}{\beta^{-1}} \\
&\leq& \beta^{1-t}
\end{eqnarray}
$$

For rounding, it is $$ \beta^{1-t} / 2 $$.

Sometimes, it can be useful to write $$fl(x) = x(1+\delta), \delta < \varepsilon$$. Then,

$$
x \oplus y = fl(fl(x) + fl(y))
$$

A natural question to ask is: what is the relative error for addition? We can analyze as follows.

$$
\begin{eqnarray}
&   & \left| \frac{(x+y) - (x \oplus y)}{x + y} \right| \\
& = & \left| \frac{x+y - fl(fl(x) + fl(y))}{x+y} \right| \\
& = & \left| \frac{\delta_1 + \delta_2 x + \delta_3 x + \delta_2 y + \delta_1 \delta_3 x + \delta_2 \delta_3 y}{x + y} \right|, |\delta_i| < \varepsilon \\
&\leq& \left| \frac{(|x| + |y|)(2\varepsilon + \varepsilon^2)}{|x+y|} \right|
\end{eqnarray}
$$

Note that if $$x$$ and $$y$$ have the same sign, then the relative error of addition $$\leq 2\varepsilon + \varepsilon^2$$. But if they have different sign, and are close in magnitude, relative error is potentially huge, because all the important digits are discarded. This is **catastrophic cancelling**.

## Interpolation

Suppose that we are given $$n$$ points $$(x_1, y_1), \cdots, (x_N, y_N)$$ with $$x_i < x_{i+1}$$ and we wish to draw a "nice" curve that passes through all of them. How do?

### Polynomial interpolation

One way is to use a polynomial of degree $$<N$$. To do these, we set up a system of equations

$$
\begin{eqnarray}
c_1 + c_2 x_1 + \cdots + c_n x_1^{n-1} & = & y_1 \\
\vdots \\
c_1 + c_2 x_n + \cdots + c_n x_n^{n-1} & = & y_n
\end{eqnarray}
$$

equivalent to the equation

$$
\begin{bmatrix}
1 & x_1 & \cdots & x_1^{n-1} \\
\vdots & \vdots & \ddots & \vdots \\
1 & x_n & \cdots & x_n^{n-1}
\end{bmatrix}
\begin{bmatrix}
c_1 \\ \vdots \\ c_n
\end{bmatrix}
=
\begin{bmatrix}
y_1 \\ \vdots \\ y_n
\end{bmatrix}
$$

The big matrix is also called the Vandermonde matrix (V), so this can be written as

$$
V \vec{c} = \vec{y}
$$

Notice that since this matrix is invertible (its determinant $$\neq 0$$), it has a unique solution.

You can also use the **Lagrange form** of the interpolating polynomial:

$$
p(x) = a_1 L_1(x) + \cdots + a_n L_n(x)
$$

where

$$
L_i(x) = \prod_{j \neq i} (x - x_j) / \prod_{j \neq i} (x_i - x_j)
$$
