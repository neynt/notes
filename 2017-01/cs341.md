# CS 341: Algorithms

Professor: Semih Salihoglu

## Introduction

An algorithm is a well-defined procedure to solve a computational problem. Types include:

- **Serial** vs. **parallel**: whether parallel computation is used.
- **Deterministic** vs. **randomized**: whether the algorithm's execution is determined completely by its input, or if it makes use of an external source of randomness to improve certain characteristics of the algorithm.
- **Exact** vs. **approximate**: describes the kind of answer the algorithm gives.

In CS 341, we mainly focus on serial, deterministic, exact algorithms.

Coming up with algorithms is fun, but not nearly all there is to do. We also analyze algorithms to understand their costs in terms of time, memory, and I/O.

## Basics

### Selection sort

```
selectionSort:
  input: X: array of n numbers
  for i = 1 ... n
    let minIndex = i
    for j = i+1 ... n
      if X[j] < X[minIndex]
        minIndex = j
    swap X[i], X[minIndex]
  return X
```

How many operations does this algorithm take on an input of size n? Each line takes one op, so
- A single run of the inner loop takes 3 ops
- The inner loop takes $$3(n-1) + 3(n-2) + ... + 3 = \frac{3n(n-1)}{2}$$ ops
- The outer loop, initialization, and swap all run n times, so they each take n ops
- In total, we use $$\frac{3n^2 + 3n}{2}$$ ops

### Merge sort

```
mergeSort:
  input: X: array of n numbers
  L = mergeSort X[1 ... n/2]
  R = mergeSort X[n/2 + 1 ... n]
  return merge L, R

merge:
  input: L, R: sorted array of m/2 numbers
  i = j = 1
  for k = 1 ... m
    if L[i] < R[j]
      Out[k] = L[i]
      i++
    else
      Out[k] = R[j]
      j++
  return Out
```

This is trickier because of the recursion. First, note that the merge itself takes $$m + 4m + 2 â‰¤ 7m$$ operations. Then, notice that the recursive calls form a tree at most $$\log_{2}n + 1$$ levels, and at level j, the subproblems are of size at most $$7n/2^j$$. So the total ops at level j is at most 7n, and mergeSort takes at most $$7n(\log_{2}n + 1) = 7n \log_{2}n + 7n$$ operations.

### Notes on CS 341

We will focus on worst case analysis. We will be sloppy with our counting. And we are mainly interested in the limiting behavior for large inputs.

## O-notation

$$T(n)$$ is in $$O(f(n))$$ if some multiple of $$T(n)$$ eventually exceeds $$f(n)$$ forever. That is, there exists $$c,n_0 > 0$$ such that $$T(n) \leq cf(n)$$ for all $$n \geq n_0$$.

For example, degree-k polynomials are in $$O(n^k)$$. Proof: Let $$c = \sum a_i$$, $$n_0 = 1$$. Then,

$$\begin{eqnarray}
T(n) &=& \sum a_{i} n^i \\
T(n) &\leq& \sum a_{i} n^i \\
T(n) &\leq& cn^k
\end{eqnarray}$$

for all $$ n \geq n_0 $$.
