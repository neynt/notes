# SE 465: Software Testing and Quality Assurance

Professor: Patrick Lam

## Code gone wild

Software usually goes wrong and there are ways to make it go wrong less and go less wrong.

- **Validation** is ensuring that the code does the right thing.
- **Verification** is ensuring that the code conforms to the specs.
- **Faults** are static defects present in the software.
- An **error** is bad internal state caused by some fault.
- **Failures** are bad external behavior.

RIP fault model:
- **Reachable**: The fault must be reachable.
- **Infection**: The program state must be wrong after reaching the fault.
- **Propagate**: The infected state must propagate to output.

Dealing with faults:
- Avoid (e.g. use Rust)
- Detect (unit testing)
- Tolerate (redundancy, isolation, checking input)

Static vs. dynamic:
- **Static** techniques: Find fault directly by analyzing the program.
  - Examples: type checking, dead code analysis, null check, bounds check, code review, formal verification.
- **Dynamic** techniques: Observe failures by running the program with particular inputs and comparing them to expected.
  - Pros: It is easy to run the program
  - Cons: We need to generate inputs, and test suites can grow unnecessarily large

Words Patrick Lam does not like:
  - "Complete testing", "exhaustive testing"
    - No way. Input space is too big.
  - "Full coverage"
    - Of what? Lines? Branches?

You should stop testing when:
  - You run out of time (open-ended exploratory testing, automatic input generation)
  - You've explored "enough" of the behaviors, use cases, program states, inputs, and statements/branches

Controllability and observability are also things.

A **test requirement** (TR) is an element of an artifact that some test case must satisfy. For example,

- "This branch is followed"
- "This method is called"

## Exploratory testing

**Exploratory testing**: Testers do it to discover interesting behavior. It's good for
- Realism.
- Finding important bugs in the shortest time.
- Evaluating risks and seeing if scripted tests are needed.

The process is as follows:
- Start with a **charter**. e.g. "Explore the product elements".
  - Decide which area of the software to test.
  - Design a test.
  - Execute a test and log bugs.
  - Repeat.

And has these outputs
- Set of bug reports
- Test notes
- Artifacts (input/output pairs)

See WaterlooWorks example.

## Control flow graph

- A **control flow graph** is a graph where nodes are sequential statements and edges mean "the program can follow this edge during execution". **Basic blocks** are sequences of nodes with a single entry and single exit where once entered will *always* run sequentially, and they can be combined into a single node. Practice drawing CFGs for programs.
- A **coverage criterion** generates of a set of test requirements given a CFG. For example, "statement coverage" means "given G, generate all nodes in G".
- A **test path** is the path in the CFG that the program follows given a particular **test input**. **Nondeterministic** programs or inputs could result in multiple test paths for a single input.
- A **test set** is a set of inputs.
- We say that a test set T **satisfies** coverage criterion C on graph G iff there exists some test path in path(T) that satisfies each test requirement generated by C.

## Finite state machine

- A higher level graph to describe your program state. Nodes are software states, and edges are transitions between them and may be guarded by preconditions and postconditions.
- You can also have test requirements and coverage for FSMs. **Simple round trip coverage** is when there is at least one round-trip path for every reachable node in G with a round-trip path. **Complete round-trip coverage** is when all round-trip paths are present.
- To obtain an FSM:
  - You can look at the software structure or specs. This is effortful, subjective, and requires system expertise.
  - Instead, you can obtain an FSM from shared state. Just identify key variables that summarize system state.

## Syntax-based testing

- You can generate test inputs using grammars, or by mutation-based testing.  
- Grammars can be regexes or CFGs.
- To obtain invalid strings, you can
  - Mutate the grammar, or
  - Misderive rules by adding/removing/permuting terminals and nonterminals
- Fuzzing:
  - Crashed WebKit using particularly bad JavaScript
  - A while back, UNIX utils crashed 1/4-1/3 of the time on random ASCII inputs
  - Mac Paint: Random inputs for testing. Monkey Lives to stop Mac Paint from exiting.
