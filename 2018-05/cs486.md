# CS 486: Intro to AI

Professor: Peter van Beek

## 2017 May 02

- What is intelligence?
  - Remembering, reasoning, planning, solving, learning, adapting
  - Understanding other intelligences and beat them
  - Understanding oneself deeply?

- Thinking is symbolic reasoning.
  - Recall Turing machines, lambda calculus
  - Can humans compute functions that are not Turing computable? >> open
    question, probably not

- Newell-Simon hypothesis/conjecture:
  - A physical symbol system suffices for intelligence.

- Four categories of AI definitions:
  - Systems that (think | act) (like humans | rationally)

- Thinking rationally
  - "Laws of thought" approach: logic and probability as normative theories.
  - "Rational agent" approach: agent does best thing to achieve its goals.

- Lots of AI applications

## 2018 May 07

- Problem solving using search
  - Find a goal state given constraints on the goal.
  - Find a sequence of actions that leads to the goal state.

- Example: n queens on an nxn board; no threats
- Example: crossword puzzles
- Example: sliding puzzles
- Example: river crossing puzzle with 100kg capacity boat, 100kg parent, two
  50kg children
- Example: propositional satisfiability (NP complete)
- Example: partition problem (equalize weights) (NP complete)
- Example: travelling saleswoman problem
- Example: set covering (minimum size committee with all skills)

- Formulate problem solving as graph search.
  - Nodes are states.
  - Edges are actions.
  - Solution is a path from initial state to goal state.
  - May have cost on edges.

- For river crossing puzzle:
  - States are assignments of {boat, parent, child1, child2} to {L, R}
    - 16 states
  - Edges are valid river crossings

- For sliding puzzles:
  - States are permutations of {1, ..., 8, empty}
    - 9! states
  - Edges are valid slides

- For n-queens:
  - States are assignments of {Q1, ..., Qn} to row index (assume Qi is in
    column i)
  - Initial state is assignment of Qi to i
  - Edges are swapping two queens

## 2018 May 09

- Skipped in favour of mental health seminar

- General search algorithm is
  - Start with list of start nodes
  - Until it's empty:
    - Pop a node, and if it isn't the goal, push successor states

- Effect of different queues
  - LIFO queue: Breadth first search
  - FIFO queue: Depth-first search
  - Priority queue: Informed search

- Distance function: 
  - g(n) is cost from initial state to n that was found
  - h(n) is heuristic estimate of cost from n to a goal
  - f(n) = g(n) + h(n) is the heuristic estimate of the total cost of the
    solution obtained down this path
  - if `h(n) <= h*(n)` for all n, then h(n) is admissible
    - with admissible h(n), `A*` will find an optimal path
  - if `h(n) <= cost(n, n') + h(n') for all n, n' a successor to n`, then h(n)
    is consistent
    - with consistent h(n), `A*` will find an optimal path
  - dominating heuristics: h2(n) dominates h1(n) if for all nodes n, h2(n) >=
    h1(n), and there's some node n' where h2(n) > h1(n').
    - thm: If h2(n) dominates h1(n), then `A*` with h1(n) expands at least as
      many node as with h2(n)

- Greedy search: Informed search with f(n) = h(n)
- Dijkstra: Informed search with f(n) = g(n)
- `A*`: Informed search with f(n) + h(n) + g(n)

- Facts about `A*`
  - Is complete, optimal, optimally efficient
    - No algorithm with the same information can do better!
  - Assumes a single goal
  - Has exponential time complexity `O(b^(εd))`, where
    - ε is the maximum relative error `1 - h(n) / h*(n)`
    - b is the branching factor
    - d is the depth of the goal node

- Iterative-deepening `A*`
  - No priority queue; instead, each iteration is a complete DFS that is cut
    off if f(n) exceeds some threshold

## Constraint satisfaction problems <!-- 2018 May 14 -->

- You have
  - A set of variables { x1, ..., xn }
  - A set of values for each variable dom(x1), ..., dom(xn)
  - A set of constraints { C1, ..., Cm }
- And want
  - An assignment to variables that satisfies the constraints
    - ... whether or not there is one?
    - ... any one?
    - ... all of them?
    - ... the optimal one, given some cost function?

- Example domains and constraints
  - Reals -- linear constraints: Gaussian elimination, linear programming
  - Integers -- linear constraints: Integer linear programming,
    branch-and-bound
  - Booleans -- propositional statements
  - Here, we will use finite domains with expressive constraint languages

- Constraint languages
  - Arithmetic operators
  - Logical operators
  - Global constraints: over an arbitrary number of variables
  - Table constraints: enumerate satisfied assignments

- Alldifferent
  - A global constraint over a set of variables that is satisfied iff all
    variables are assigned a different value

- Examples
  - Sudoku:
    - 81 variables x1, ..., x81 for each grid square
    - Rows: alldifferent(x1, ..., x9)
    - Columns: alldifferent(x1, x10, ..., x73)
    - Squares: alldifferent(x1, x2, x3, x10, ..., x21)
    - Given values
  - n-queens: Variables are x1, ..., x4; xi is the row of the queen in column i
  - Crosswords: Variables are squares, domain is latin alphabet

### Constraint propagation

- Detail on constraints
  - An assignment is x = a, where a in dom
  - A tuple t over a list of variables {x1, ..., xk} is a list of values (a1,
    ..., ak)
    - like a set of assignments
  - In a tuple t, t[xi] is the value for variable xi.
  - A constraint C defined over vars(C) specifies the allowed combination of
    values for the variables in vars(C).
  - vars(C) is the **scope** or **scheme** of the constraint
  - len(vars(C)) is the **arity** of the constraint
    - Unary constraint: 1
    - Binary constraint: 2
    - Non-binary: > 2
  - In a binary CSP, all constraints are binary.

- Intensional vs. extensional
  - Intensional is implicit. Like "x1 != x2 and |x1 - x2| != 1"
  - Extensional is explicit. Like {(1,3), (1,4), (2,4), (3,1), (4,1), (4,2)}.
    - AKA the table constraint.

- Local consistency: Arc consistency
  - Given a constraint, remove a value from the domain of a variable if it
    cannot be part of a solution according to that constriant.
  - Formally:
    - Let C be a constraint
    - Domain support:
      - Let x in vars(C)
      - Let a in dom(x)
      - x has a domain support in C if there exists t in C such that t[x] = a
        and t[y] in dom(y) for every y in vars(C).
    - C is arc consistent iff for all x in vars(C), every value a in dom(x) has
      a domain support in C.
      - i.e. if it's possible that x = a can solve the CSP.
  - A CSP is arc consistent if every constraint is arc consistent
  - You can make a CSP arc consistent by repeatedly removing unsupported values
    from the domains.

- Arc consistency algorithm
  - ac: Q:(variable * constraint) list -> boolean
    - while Q is not empty:
      - pop (x, C) from Q
      - if revise(x, C):
        - if dom(x) is empty: return false
        - else: add pairs to Q
    - return true
  - revise: x:variable -> C:constraint -> boolean
    - change = false
    - for a:value in dom(x):
      - if there's no domain support for a in C:
        - remove a from dom(x)
        - change = true
    - return change

<!-- 2018 May 16 -->

### Backtracking search

- Backtracking search: DFS of search tree

- Algorithm template:
  - backtrack(assignment, csp):
    - if assignment is complete then solution found
    - var <- select next variable
    - for val in dom(var):
      - save(csp)
      - add var = val to assignment
      - if propagate(assignment, csp):
        - backtrack(assignment, csp)
      - restore(csp)

- Backtracking algorithms:
  - Naive backtracking (BT)
    - No constraint propagation
    - Backtrack in time
  - Forward checking (FC)
    - Maintain arc consistency on all constraints with exactly one
      uninstantiated variable
    - Backtrack in time
  - Maintaining arc consistency (MAC):
    - Maintain arc consistency on all constraints with at least one
      uninstantiated variable
    - Backtrack in time
  - MAC is the best. Only use FC if MAC is guaranteed to not help at all.

### Local search

- Local search
  - Does both satisfaction and optimization problems
  - No guaranteed that a solution will be found, even if it exists
  - Cannot find a provably optimal solution
  - Finds locally optimal solutions, not necessarily globally optimal

- Notation
  - S := set of states
  - c : S -> R := cost function
  - N : S -> 2^S := neighborhood function

- Optimality
  - Globally optimal: solution `s*` in S with `c(s*) <= c(s)` for all s in S.
  - Locally optimal: solution `s+` in S with `c(s+) <= c(s)` for all s in
    `N(s+)`.

- For CSPs
  - Consider some constraints hard (must be satisfied); others soft (cost
    function +1 for each unsatisfied constraint)

- Algorithm template:
  - s = some initial complete assignment
  - k = 0
  - do
    - r = neighbor of s
    - if c(r) - c(s) < tk then
      - s = r
    - k += 1
  - until stopping criteria satisfied
  - return best s

- Stopping criteria
  - Maximum # of iterations
  - Solution of low enough cost
  - Number of iterations since last (big enough) improvement too large

- Choices
  - Initial feasible solution
    - Can be random, or "good" according to some heuristic
  - Neighborhood function
    - Small neighborhood: Easily explored, low quality solutions
    - Large neighborhood: Expensive
  - Selecting r
    - First improvement (pick first improving neighbor)
    - Best improvement (go through all neighbors and pick best one)

- Thresholds
  - Iterative improvement
  - Threshold accepting
    - Accept worse cost neighbors with diminishing threshold
    - Variation: simulated annealing. (accept worse neighbors with a gradually
      decreasing probability)
    - Variation: tabu search. (accept worse neighbors based on a list of legal
      neighbors)

- Improvements
  - Multi-starts: Try multiple initial solutions
  - Multi-level: Use different neighborhoods throughout

- Example: Neighborhoods for 8-queens
  - Transpose: swap adjacent queens. O(n) neighbors
  - Insert: move a queen, displacing queens in between. O(n^2) neighbors
  - Swap: swap two queens. O(n^2) neighbors
  - Block insert: move a subsequence of queens. O(n^3) neighbors.

<!-- 2018 May 22 --> <!-- Missed a bit due to photo session. -->

- Example: Results for TSP
  - Theoretical results
    - Exact neighborhood: When every local optimum is also a global optimum
      - Must be exponential in size, unless P = NP
    - Non-exact neighborhoods
      - Cost of local optimum can be arbitrarily far from global optimum :(
      - Local search can still take exponential number of steps to reach a
        local optimum
  - Empirical results
    - Best local search algorithms get within 1.5-2.5% of optimal
    - Can do a million cities in under an hour

- Example: Local search for TSP
  - Nodes are permutations of cities
  - Cost is cost of tour
  - Neighborhood function 2-opt:
    - Delete two edges from the tour to break it into two paths, then reconnect
      in all possible ways

- Example: Local search for SAT
  - GSAT: Keeping flipping the boolean variable that minimizes the number of
    unsatisfied clauses, do so maxTries times

- Genetic algorithms
  - Create a population of solutions, assign fitness according to how good the
    solution is, breed solutions randomly weighted by goodness, possibly mutate
    their children, and pick the fittest individual

<!-- 2018 May 23 -->

## Reasoning under uncertainty

- Types of uncertainty:
  - Partial observability: incomplete knowledge of world
  - Nondeterminism: actions have random consequences

- Random variable: is a thing

- Joint probability distribution
  - Assignment of a probability to each atomic event for a set of random
    variables
  - Atomic event is cross product of domains of your random variables

- Holmes scenario:  
  - A: Alarm goes off
  - B: Burglary in progress
  - R: Radio runs report
  - W: Watson calls saying alarm is going
  - G: Gibson calls saying alarm is going

- Important rules:
  - Product rule: P(X,Y) = P(X|Y)P(Y) = P(Y|X)P(X)
  - Sum rule: P(X=a) = sum over b in dom(Y) of P(X=a|Y=b)P(Y=b)
  - Bayes rule: P(Y|X) = P(Y)P(X|Y)/P(X)
  - Chain rule: P(X1,...,Xn) = product for i from 1 to n of P(Xi|Xi-1,...,X1)

- Independence:
  - X is ind. of Y if P(X|Y) = P(X).
  - Implies P(Y|X) = P(Y).

- Examples of (non)independence
  - Watson is independent of Gibbon? No

<!-- 2018 May 28 -->

- Conditional independence:
  - X is cond. ind. of Y given Z if P(X|Y,Z) = P(X|Z).
  - Can swap X and Y.
  - Allows simplification of chain rule:
    - P(X1, ..., Xn) = ... = P(X1), if X2, ..., Xn cond. ind. of X1.

- Bayesian network
  - DAG
  - Nodes are random variables
  - Directed edges are "influence"
  - Each node has a conditional probability table of the effect of parents on
    the node
  - Two ways to understand them semantically:
    - As a representation of the entire joint probability distribution
    - As an encoding of conditional independence assumptions
  - Correct only if each node is conditionally independent of its predecessors
    in the node ordering, given its parents
    - In practice, you'll need to look at many orderings
    - For us, any ordering works

- Example: Bayesian network for burglary scenario
  - B, E -> A
  - E -> R
  - A -> G, W
  - Assumptions made: P(W|A) = P(W|A,B) = P(W|A,...)
  - From "disease" to "symptom"
  - 16 probabilities

- Another one (drop R)
  - W -> G, A
  - G -> A
  - A -> B, E
  - B -> E
  - Using formula for network:
    - P(W,G,A,B,E) = P(W)P(G|W)P(A|W,G)P(B|A)P(E|B,A)
  - Using chain rule:
    - P(W)P(G|W)P(A|W,G)P(B|W,G,A)P(E|W,G,A,B)
  - Also correct
  - Comparison with previous one:
    - Number of probabilities: 2 + 4 + 8 + 4 + 8 = 26
  - From "symptom" to "disease"

- Another one
  - W, G -> A
  - A -> B, E
  - Using formula for network:
    - P(W,G,A,B,E) = P(W)P(G|W)P(A|W,G)P(B|W,G,A)P(E|W,G,A,B)
  - Using chain rule:
    - P(W,G,A,B,E) = P(W)P(G|W)P(A|W,G)P(B|A)P(E|A)
  - Assumptions made:
    - P(G|W) = P(G)? NOPE. Incorrect network.

- Another one (no conditional independence assumptions)
  - W -> G,A,B,E
  - G -> A,B,E
  - A -> B,E
  - B -> E
  - Correct
  - But, you need 2 + 4 + 8 + 16 + 32 = 62 probabilities

<!-- 2018 May 30 -->

- After this lecture, you will be able to do all of A2
- A2 groups: Aim for at least two people. Reduces marking load.

- Inference in Bayesian networks
  - P(Query | Evidence)

- Kinds of probabilistic inference
  - Diagnostic
    - P(cause | effect), P(disease | symptom)
    - e.g. B -> A -> W. P(B | W) = ?
  - Causal inferences
    - P(effect | cause), P(symptom | disease)
    - e.g. B -> A -> W. P(W | B) = ?
  - Intercausal inferences
    - Between causes of a common effect
    - P(cause1 | cause2, effect), P(disease1 | disease2, symptom)
    - e.g. B, E -> A. P(B | E, A) = ?
    - Note: If P(B | A) >> P(B | E, A), then a bit of A is explained away
  - Mixed inferences
    - Combining diagnostic, causal, and intercausal
    - e.g. E -> A -> W. P(A | W, !E) = ?

- Examples of probabilistic inference
  - If Watson calls:
    - +E, +B, +R, 1W, +G
    - Note that Watson doesn't actually give us all that much information about
      whether a burglary is happening, because he's so unreliable. Chance goes
      from .0001 to .0002
  - If radio reports earthquake:
    - ++E, =B, 1R, +W, +G
  - Consider E and B.
    - If Watson calls, +E and +B.
    - If, in addition to that, R, then ++E and -B.
      - Wait, -B? Yes. R "explains away" some of the W.

- Example query using our Bayesian network
  -   P(!B | W,G)
    = P(!B,W,G) / P(W,G)
    = P(!B,W,G) / sum over dom(B) of P(B=b,W,G)
    = P(!B,W,G) / (P(!B,W,G) + P(B,W,G))
  - Where:
    -   P(!B,W,G)
      = sum over e, a, r of P(!B,E=e,A=a,R=r,G,W)
      = sum over e, a, r of P(!B)P(E=e)P(A=a|!B,E=e)P(R=r|E=e)P(W|A=a)P(G|A=a)
        (using formula for Bayesian network)
    - Can somewhat simplify by factoring

- Examples of Bayesian networks
  - In general: What's observable? What's latent?
    - Top layer: Situations and root causes
    - Mid layer: Events
    - Bot layer: Sensor outputs and reports
  - Example: Nuclear power plant
  - Example: Fire alarms
  - Example: Diagnosing diabetes
    - "One gender lives longer; one gender dies earlier with a surprising death
      peak in early 20s. I think it's called testosterone?"
  - Example: User needs assistance
  
## Slides 8

- Dynamic systems
  - What if we could reason over time?
  - Have a set of states S
  - Have cond. prob. tables P(St+1 | St, ..., S0)
  - Like a Bayesian network with one RV per time slice

- Markov chain
  - Based on the Markov assumption: That P(St+1 | St, ..., S0) = P(St+1 | St)
  - Stationary: If P(St+1 | St) is the same for all t

- Hidden Markov model
  - Like a Markov chain, but also have observations Ot: P(Ot | St)
  - We don't actually know what state we're in; we have to infer it via observations!!
  - holy shiiiiit

- Inference in temporal models
  - Monitoring: P(St | O1, ..., Ot)
  - Prediction: P(St+k | O1, ..., Ot)
    - Example: Weather, stocks
  - Hindsight:  P(Sk | O1, ..., Ot)
    - Example: Crime scene
  - Most probable explanation: argmax over S0, ..., St of P(S0, ..., St | O1, ..., Ot)
    - Example: Speech recognition
