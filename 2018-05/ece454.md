# ECE 454: Distributed Computing.

Professor: Wojciech Golab.

## 2018 May 1

- Why build distributed systems?
  - [[Resource sharing saves money.]]
  - [[Simplifies business processes.]]
  - [[Scales beyond what a centralized system can.]]
  - [[Users may be distributed.]]

- Anecdote: Lord Kelvin vs. Edward Orange Wildman Whitehouse.
  - Entrepreneur Whitehouse fried transatlantic cable by pumping voltage,
    against engineer Kelvin's warning.

- Middleware: Offers a single-system view between applications and operating
  systems on different machines.
  - Common middleware services
    - [[Communication (e.g. add job to remote queue)]]
    - [[Transactions (e.g. access independent services atomically)]]
    - [[Service composition (e.g. Google map with weather forecast)]]
    - [[Reliability (e.g. replicated state machine)]]

- Goals of distributed systems:
  - Support resource sharing
  - Make distribution transparent (7 types... memorize them)
    - Access: representing and accessing resources
    - Location: putting resources somewhere
    - Migration: moving resources
    - Relocation: moving resources while in use
    - Replication: replicating resources
    - Concurrency: sharing resources
    - Failure: failing and recovering resources
  - Be open, that is:
    - [[Interopable]]
    - [[Composable]]
    - [[Extensible]]
    - [[Policy separate from mechanism]]
  - Be scalable
    - [[Size]]
    - [[Geography]]
    - [[Administration]]
    - Avoid common mistakes that limit scalability:
      - Centralized services (e.g. a single server)
      - Centralized data (e.g. a single telephone book database)
      - Centralized algorithms (e.g. routing based on complete information)

## 2018 May 2

- Types of distribution transparency:
  - Access
  - Location
  - Relocation
  - Migration
  - Replication
  - Concurrency
  - Failure

- (2/3)c is the fastest light goes

- Scaling techniques:
  - Partitioning and distribution: Splitting stuff up
    - Example: Original DNS, which is a tree with zones
  - Replication: Having multiple copies of a thing
    - Example: memcached to speed up web apps
    - Can also have look-aside caching (look at cache and storage in parallel)

- Falsehoods programmers believe about distro
  - The network is reliable
  - The network is secure
  - The network is homogeneous
  - The topology does not change
  - Latency is zero
  - Bandwidth is infinite
  - Transport cost is zero
  - There is one administrator
- "Recall n of these" was on a previous exam

- Types of distributed systems
  - Website, web services
  - High performance computing (HPC)
    - Multiprocessor vs. multicomputer
    - Cluster computing
      - There is a master node that coordinates
    - Grid computing
    - Cloud computing
  - Transaction processing
  - Enterprise application integration
  - Internet of things (distributed pervasive systems)
  - Sensor networks
    - In-network data processing: When the sensors calculate things themselves
      rather than shunting data directly to the operator
    - Example: smart irrigation

- Shared memory vs. message passing
  - Shared memory is parallel computing
  - Message passing is distributed computing
  - Some theorists say they're both distributed computing

- Big Data: In one minute, many many things are happening.

## 2018 May 3

- Architecture (triggered)
  - ... is Components connected by Connectors

- Architectural styles (fuck)
  - layered
  - object-based (e.g. Enterprise Java Beans)
  - data-centred
  - event-based (e.g. Kafka)

- Multi-tiered architectures
  - Example: Client and Server are the two tiers. Then UI, App, and DB can be
    split across them in five ways (between the divisions, possibly with some
    software layer split between the two)

- Peer-to-peer systems
  - e.g. Chord: DHT with a ring overlay network (coool)
  - Resistant to **churn** (nodes entering and leaving)
  - Finger table: Kinda like skiplist. Allows lookup in log(n)

## 2018 May 8

- Hybrid architectures
  - Example: Bittorrent
  - Client gets .torrent file from website
  - Tracker tells you where nodes are
  - Nodes have actual data (this is the P2P part)
  - To deal with this, some police upload garbage to poison the data.

- Self-management: Use a feedback control loop to adjust system based on
  sensors

- Module 3: Processes

- Lightweight processes
  - For A1: OOM errors can actually mean that you ran out of processes.

- Multi-threaded servers
  - Often: one dispatcher thread, multiple worker threads

- Virtualization
  - Can be in a runtime environment (like JRE)
  - Can be on an OS running on top of a virtual machine monitor
  - In A2, whene prof spins up tha doop

- Types of message passing
  - Application-specific: Like Skype.
  - Application-independent: Like X Windows.

- Clusters
  - Three tiers
    - Load balancer(s)
    - Application/compute server
    - Distributed filesystem or database

## 2018 May 9

- Netcat examples.
  - nc www.uwaterloo.ca 80
  - GET / HTTP/1.0
  - GET / HTTP/1.1
    - Keeps connection open, as an HTTP/1.1 feature!
  - nc -l [-p] 10000
  - nc localhost 10000
- Kafka examples.

- Remote procedure calls.
  - Client stub: Bit of code on the client that sends the call
  - Server stub: Bit of code on the server that receives the call
  - Marshalling: Packing parameters into a message
    - Does endianness transformations
  - IDL: Interface Definition Language
  - Synchronous: Client waits for return value.
    - Like usual call center holds.
  - Asynchronous: Client doesn't wait. Instead, server calls client.
    - Like if a call center just takes your number and calls you back.
  - One-way: Client doesn't wait or care.

- Message queuing model.
  - Alternative to RPCs that use a shared scalable message queue.
  - Primitives:
    - Put: Append message to queue.
    - Get: Blocking get next message from queue.
    - Poll: Non-blocking get (option) next message from queue.
    - Notify: Install handler for when message is put into queue.

- Message-oriented middleware: Characterized by async message passing.
  - JMS: Java Message Service. Supports message queues and pubsub.

- Coupling among processes
  - Referential coupling: One process explicitly references another.
  - Temporal coupling: Communication processes must simply by running.

- RPC vs. MOM
  - RPC:
    - for two-way communication requiring a response
    - middleware linked into the client and server, no additional software
      required
    - tighter coupling
  - MOM:
    - response not required; just publishing information (like Trump's tweets)
    - middleware is a separate component between producer and consumer
    - looser coupling

- RPC demo

## 2018 May 10

- Apache Thrift.
  - Protobuf by Facebook for the entire world.
  - Software stack:
    - Server
    - Processor (compiler generated)
    - Protocol (JSON, compact, ...)
    - Transport (TCP, HTTP, ...)
  - Learn the IDL syntax
    - Types: bool, byte, i16, i32, i64, double, binary, string, void
    - Containers: list, set, map
    - Other types: const, typdef, enum, struct, exception
    - Field modifiers: required, optional, default values
    - Services and procedures: service, extends, oneway
    - Namespace: Java package (lel)
  - Field numbers can never be reused

## 2018 May 15

- Asynchronous RPC.
  - Must use non-blocking socket and transport.
  - Must provide TAsyncClientManager instance to handle callbacks.
  - Must provide a callback via interface AsyncMethodCallback.
  - May need synchronization between callback and caller, e.g. with Condition
    or CountDownLatch.

- Multi-threaded server.
  - THsHaServer: "Thrift Half Synchronous Half Asynchronous" monstrosity.
  - For assignment: Limit your worker thread pool to AT MOST 64 worker threads.
  - Server implementations:
    - `TSimpleServer`: Single thread, blocking IO
    - `TNonblockingServer`: Single thread, nonblocking IO
    - `THsHaServer`: One thread for IO, worker thread pool
    - `TThreadedSelectorServer`: IO thread pool, worker thread pool
    - `TThreadPoolServer`: One thread accepts connections, each connection has
      a dedicated thread from a pool
    - Assignment hint: Use either THsHaServer or TThreadPoolServer.
      - You probably want the fastest one... as long as it doesn't crash.

- Thrift protocols.
  - TBinaryProtocol: Straightforward binary format.
  - TCompactProtocol: Compact binary format with varints and stuff.
    - Usually the fastest, since network is slower than CPU.
  - TJSONProtocol: Uses bloated JSON format.

## 2018 May 16

- On the assignment.
  - When you're processing requests, two main strategies you can use to process
    batches.
  - Strategy #1: Send entire batch to one backend.
    - Faster/"fairer" with lots of parallel clients.
  - Strategy #2: Break up the batch.
    - Faster response time with a single threaded client.

- Quiz questions.
  - Turing Award winner for 2013: Leslie Lamport
  - Google doesn't depend on: global clock
  - Layered architecture is: more coupled than object-based
  - Vertical distribution is: adding more power to a machine
  - Hash partitioning is popular for: horizontal distribution
  - IPC is expensive because: it requires a context switch <!-- 2018 May 17 -->
  - In an RPC framework, parameters are typically: passed by value.
  - The purpose of the service handler in an RPC server is: not to call the
    server stub; the server stub calls the service handler.
  - The Intel IA-64 architecture is: Bi-endian
  - RPC is an example of: transient communication
  - What is NOT a message-oriented middleware: RPC
  - Not a keyword in Thrift IDL: synchronous
  - Java thread invoking async Thrift RPC will have callback executed in:
    different thread
  - Thrift Java server that does not use a single thread to accept network
    connections: TThreadedSelectorServer
  - TCompactProtocol uses compression to reduce the size of Thrift messages:
    False; is done by variable length encoding
  - How Thrift treats the "optional" keyword: Ignores keyword, allows caller to
    either provide or not provide the argument.
  - Non-blocking sockets are required in: Just the asynchronous client.
  - Vertical distribution is spreading different layers across multiple
    physical tiers: true.

## 5b. Thrift additional notes

- Bunch of examples

## 6. Distributed file systems

- ecelinux servers use a distributed file system. Proof: Log in and type
  `mount`. NFS is a distributed file system.

- Access models:
  - Remote access model: "reading a book at the library"
  - Upload/download model: "checking a book out from the library"
  - Often, upload/download model is preferred

- NFS
  - Network File System
  - Developed at Sun in 1984
  - e.g. ecelinux home folders are NFSv4
  - Uses client-side caching
  - Changes are flushed on file close
  - Consistency handling is implementation-dependent
  - NFSv4 lets the server delegate authority
  - Uses RPCs internally
  - Problem: Not that great at large files
    - Striping: splitting files into multiple chunks

<!-- 2018 May 23 -->

- Semantics of file sharing
  - UNIX semantics:
    - Every operation immediately visible to everyone.
  - Session semantics:
    - Changes visible to others only after file is closed.
  - Immutable files:
    - No updates are possible.
  - Transactions:
    - ATOMICITY

<!-- 2018 May 24 -->

- GFS
  - Google File System
  - Master:
    - Coordinates several Chunk Servers
    - Stores metadata about files and chunks
    - Polls chunk servers to keep metadata consistent
  - To read, the Master redirects the client to the appropriate chunk server
  - To write, there's cool pipelining involving primary and secondary replicas

- Quiz!
  - The advantage of upload/download model is: Lower latency in write-intensive
    workloads.
  - "Striping" is: Placing chunks of the same file on different servers
  - In GFS, a client reads data by: reading metadata from the master and data
    from the chunk servers
  - In GFS, a client writes data by: writing to one replica, which chains it to
    other replicas
  - GFS vs HDFS: Files are mutable in GFS, append-only in HDFS

## 7. MapReduce (part a)

- History: Lambda calculus
- Google: GFS: '03, MapReduce: '04
- Hadoop: 2005 open source version of MapReduce created by Doug Cutting (mostly
  implemented by Doug Cafarella)

<!-- 2018 May 29 --> <!-- Missed first 15m -->

- Stages of MapReduce:
  - Map: Takes input, typically from a distributed file system, and emits keyed
    output values.
  - Shuffle
  - Sort
  - Reduce: Takes mapper's output values with a common key and produces a
    single output value.

- Example: Word count
  - mapper(filename, file-contents): for word in file-contents: emit (word, 1)
  - reducer(word, values): emit (word, sum(value for value in nvalues))

<!-- 2018 May 30 --> <!-- Missed first 3m -->

- Mapper example code
  - Hadoop MapReduce string tokenizer may behave differently by default from
    that of Spark! BE WARNED.

- Reducer example code
  - If you print to stdout in your mapper, you don't actually see it in your
    console! It get sent to logs, since your mapper code isn't actually running
    on the master node.

- Driver example code

- How to run on ecelinux
  - Use `hadoop classpath` to get the classpath
  - Hint: To complete assignment 2, you need to understand
    `job.setNumReduceTasks()`

- Demo
  - `part-r-00000`: r is for reducer. m is for mapper.
  - Cool little exercise:
    - Take the driver, and experiment with things like
      - What if we don't use a combiner?
      - What if I don't use a reducer?
        - Hadoop uses the identity reducer by default
  - We will get a DADOOP cluster. Will cost the school about $300/day
    - And if you start working on the second assignment two days before the
      deadline, you're going to die.
    - There will be no extensions because we will run out of money at some
      point and we'll have to share the cluster down.

## 7. MapReduce b: Programming patterns

- Counting terms
  - Simplest solution:
    - Mapper: emit (term, 1) for all terms
    - Reducer: emit (term, sum(counts))
  - Can also do a bit of counting in the Mapper:
    - Mapper: accumulate counts by words, then emit (term, counts[term]) for all terms
      - Can run out of memory
  - Alternatively, use combiner that's identical to the reducer

- Selection (i.e. Filter)
  - Return input elements that satisfy some predicate
  - Mapper: key -> t -> if t satisfies predicate then emit(t, null)

- Projection
  - Return subset of fields
  - Mapper: key -> t -> emit(project t, null)
  - Reducer: t -> n -> emit(t, null) # n is an array of nulls
    - The reducer eliminates duplicates

<!-- 2018 May 31 -->

- Inverted index
  - Aside: I have no idea why they call this "inverted"; it's literally just an
    index
  - Produce a mapping from term to document ID
  - Mapper :: id: docid -> d: doc -> emit(t, id) for t: term in d
  - Reducer :: t: term -> docids: docid list -> emit(t, docids)

- Thunderstorm: Stay safe. Bad things happen to good people.

- Cross-correlation
  - Set of tuples. For each pair of items, calculate the number of tuples where
    these items co-occur.
  - Pairs approach:
    - Slower, simpler
    - Mapper :: () -> items -> emit((i, j), count 1) for i in items for j in items if j > i
    - Reducer :: (i, j) -> counts -> emit((i, j), sum(counts))
  - Stripes approach:
    - Faster, more complex, more memory on mapper
    - Mapper :: () -> items ->
        for i in items:
          H = map from item to count
          for j in items if j > i:
            h[j] += 1
          emit(i, H)
    - Reducer :: i -> stripes ->
        H = mconcat stripes
        for (k,v) in H:
          emit((i,k), v)
  - TODO: Exercise: do cross-correlation assuming a combiner is used.
  - Stripes is better because it permits more combining.
